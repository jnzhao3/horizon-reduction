#!/bin/bash
#SBATCH --job-name=aorl
#SBATCH --open-mode=append
#SBATCH -o /global/scratch/users/jenniferzhao/logs/%A_%a.out
#SBATCH -e /global/scratch/users/jenniferzhao/logs/%A_%a.err
#SBATCH --time=36:00:00
#SBATCH --mem=64G
#SBATCH --cpus-per-task=4
#SBATCH --gres=gpu:A5000:1
#SBATCH --account=co_rail
#SBATCH --partition=savio4_gpu
#SBATCH --qos=rail_gpu4_high
#SBATCH --requeue
#SBATCH --array=1-48%16

TASK_ID=$((SLURM_ARRAY_TASK_ID-1))
PARALLEL_N=2
JOB_N=96

COM_ID_S=$((TASK_ID * PARALLEL_N + 1))
source ~/.bashrc
micromamba activate aorl
export PYTHONPATH="../:${PYTHONPATH}"

declare -a commands=(
 [1]='python3 train_value.py --run_group train_value2_1 --env_name humanoidmaze-medium-navigate-oraclerep-v0 --agent ../agents/gcfql.py --dataset_dir ../../scratch/data/humanoidmaze-medium-navigate-v0 --train_data_size 100000 --offline_steps 100 --save_interval 100 --save_dir ../../scratch/gcfql/ --agent.alpha 300 --agent.actor_type best-of-n --agent.train_goal_proposer=True --agent.actor_hidden_dims 512,512,512,512 --agent.value_hidden_dims 512,512,512,512 --agent.batch_size 256 --agent.num_actions 8 --agent.num_qs 2 --agent.subgoal_steps 50 --json_path ../jsons/data.json --agent.awr_invtemp 1.0 --agent.discount 0.995 --restore_path ../../scratch/gcfql/horizon-reduction/gcfql_maze_oracle4_8/sd000_1456162036334.s_27680590_6.20250829_185905_857.gcfql_maze_oracle4_8 --restore_epoch 2000000 --q_pred_calc batch --log_interval 10 --eval_interval 50'
 [2]='python3 train_value.py --run_group train_value2_1 --env_name humanoidmaze-medium-navigate-oraclerep-v0 --agent ../agents/gcfql.py --dataset_dir ../../scratch/data/humanoidmaze-medium-navigate-v0 --train_data_size 100000 --offline_steps 100 --save_interval 100 --save_dir ../../scratch/gcfql/ --agent.alpha 300 --agent.actor_type best-of-n --agent.train_goal_proposer=True --agent.actor_hidden_dims 512,512,512,512 --agent.value_hidden_dims 512,512,512,512 --agent.batch_size 256 --agent.num_actions 8 --agent.num_qs 2 --agent.subgoal_steps 50 --json_path ../jsons/data.json --agent.awr_invtemp 1.0 --agent.discount 0.995 --restore_path ../../scratch/gcfql/horizon-reduction/gcfql_maze_oracle4_8/sd000_1456162036334.s_27680590_6.20250829_185905_857.gcfql_maze_oracle4_8 --restore_epoch 2000000 --q_pred_calc sample --log_interval 10 --eval_interval 50'
 [3]='python3 train_value.py --run_group train_value2_1 --env_name humanoidmaze-medium-navigate-oraclerep-v0 --agent ../agents/gcfql.py --dataset_dir ../../scratch/data/humanoidmaze-medium-navigate-v0 --train_data_size 100000 --offline_steps 100 --save_interval 100 --save_dir ../../scratch/gcfql/ --agent.alpha 300 --agent.actor_type best-of-n --agent.train_goal_proposer=True --agent.actor_hidden_dims 512,512,512,512 --agent.value_hidden_dims 512,512,512,512 --agent.batch_size 256 --agent.num_actions 8 --agent.num_qs 2 --agent.subgoal_steps 50 --json_path ../jsons/data.json --agent.awr_invtemp 1.0 --agent.discount 0.995 --restore_path ../../scratch/gcfql/horizon-reduction/gcfql_maze_oracle4_8/sd000_1453467320942.s_27680626_4.20250829_185906_336.gcfql_maze_oracle4_8 --restore_epoch 2000000 --q_pred_calc batch --log_interval 10 --eval_interval 50'
 [4]='python3 train_value.py --run_group train_value2_1 --env_name humanoidmaze-medium-navigate-oraclerep-v0 --agent ../agents/gcfql.py --dataset_dir ../../scratch/data/humanoidmaze-medium-navigate-v0 --train_data_size 100000 --offline_steps 100 --save_interval 100 --save_dir ../../scratch/gcfql/ --agent.alpha 300 --agent.actor_type best-of-n --agent.train_goal_proposer=True --agent.actor_hidden_dims 512,512,512,512 --agent.value_hidden_dims 512,512,512,512 --agent.batch_size 256 --agent.num_actions 8 --agent.num_qs 2 --agent.subgoal_steps 50 --json_path ../jsons/data.json --agent.awr_invtemp 1.0 --agent.discount 0.995 --restore_path ../../scratch/gcfql/horizon-reduction/gcfql_maze_oracle4_8/sd000_1453467320942.s_27680626_4.20250829_185906_336.gcfql_maze_oracle4_8 --restore_epoch 2000000 --q_pred_calc sample --log_interval 10 --eval_interval 50'
 [5]='python3 train_value.py --run_group train_value2_1 --env_name humanoidmaze-medium-navigate-oraclerep-v0 --agent ../agents/gcfql.py --dataset_dir ../../scratch/data/humanoidmaze-medium-navigate-v0 --train_data_size 100000 --offline_steps 100 --save_interval 100 --save_dir ../../scratch/gcfql/ --agent.alpha 300 --agent.actor_type best-of-n --agent.train_goal_proposer=True --agent.actor_hidden_dims 512,512,512,512 --agent.value_hidden_dims 512,512,512,512 --agent.batch_size 256 --agent.num_actions 8 --agent.num_qs 2 --agent.subgoal_steps 50 --json_path ../jsons/data.json --agent.awr_invtemp 1.0 --agent.discount 0.995 --restore_path ../../scratch/gcfql/horizon-reduction/gcfql_maze_oracle4_8/sd000_1448342040171.s_27680619_3.20250829_185930_100.gcfql_maze_oracle4_8 --restore_epoch 2000000 --q_pred_calc batch --log_interval 10 --eval_interval 50'
 [6]='python3 train_value.py --run_group train_value2_1 --env_name humanoidmaze-medium-navigate-oraclerep-v0 --agent ../agents/gcfql.py --dataset_dir ../../scratch/data/humanoidmaze-medium-navigate-v0 --train_data_size 100000 --offline_steps 100 --save_interval 100 --save_dir ../../scratch/gcfql/ --agent.alpha 300 --agent.actor_type best-of-n --agent.train_goal_proposer=True --agent.actor_hidden_dims 512,512,512,512 --agent.value_hidden_dims 512,512,512,512 --agent.batch_size 256 --agent.num_actions 8 --agent.num_qs 2 --agent.subgoal_steps 50 --json_path ../jsons/data.json --agent.awr_invtemp 1.0 --agent.discount 0.995 --restore_path ../../scratch/gcfql/horizon-reduction/gcfql_maze_oracle4_8/sd000_1448342040171.s_27680619_3.20250829_185930_100.gcfql_maze_oracle4_8 --restore_epoch 2000000 --q_pred_calc sample --log_interval 10 --eval_interval 50'
 [7]='python3 train_value.py --run_group train_value2_1 --env_name humanoidmaze-medium-navigate-oraclerep-v0 --agent ../agents/gcfql.py --dataset_dir ../../scratch/data/humanoidmaze-medium-navigate-v0 --train_data_size 100000 --offline_steps 100 --save_interval 100 --save_dir ../../scratch/gcfql/ --agent.alpha 300 --agent.actor_type best-of-n --agent.train_goal_proposer=True --agent.actor_hidden_dims 512,512,512,512 --agent.value_hidden_dims 512,512,512,512 --agent.batch_size 256 --agent.num_actions 8 --agent.num_qs 2 --agent.subgoal_steps 50 --json_path ../jsons/data.json --agent.awr_invtemp 1.0 --agent.discount 0.995 --restore_path ../../scratch/gcfql/horizon-reduction/gcfql_maze_oracle4_8/sd000_1438812371566.s_27680617_1.20250829_190015_646.gcfql_maze_oracle4_8 --restore_epoch 2000000 --q_pred_calc batch --log_interval 10 --eval_interval 50'
 [8]='python3 train_value.py --run_group train_value2_1 --env_name humanoidmaze-medium-navigate-oraclerep-v0 --agent ../agents/gcfql.py --dataset_dir ../../scratch/data/humanoidmaze-medium-navigate-v0 --train_data_size 100000 --offline_steps 100 --save_interval 100 --save_dir ../../scratch/gcfql/ --agent.alpha 300 --agent.actor_type best-of-n --agent.train_goal_proposer=True --agent.actor_hidden_dims 512,512,512,512 --agent.value_hidden_dims 512,512,512,512 --agent.batch_size 256 --agent.num_actions 8 --agent.num_qs 2 --agent.subgoal_steps 50 --json_path ../jsons/data.json --agent.awr_invtemp 1.0 --agent.discount 0.995 --restore_path ../../scratch/gcfql/horizon-reduction/gcfql_maze_oracle4_8/sd000_1438812371566.s_27680617_1.20250829_190015_646.gcfql_maze_oracle4_8 --restore_epoch 2000000 --q_pred_calc sample --log_interval 10 --eval_interval 50'
 [9]='python3 train_value.py --run_group train_value2_1 --env_name humanoidmaze-medium-navigate-oraclerep-v0 --agent ../agents/gcfql.py --dataset_dir ../../scratch/data/humanoidmaze-medium-navigate-v0 --train_data_size 100000 --offline_steps 100 --save_interval 100 --save_dir ../../scratch/gcfql/ --agent.alpha 300 --agent.actor_type best-of-n --agent.train_goal_proposer=True --agent.actor_hidden_dims 512,512,512,512 --agent.value_hidden_dims 512,512,512,512 --agent.batch_size 256 --agent.num_actions 8 --agent.num_qs 2 --agent.subgoal_steps 50 --json_path ../jsons/data.json --agent.awr_invtemp 1.0 --agent.discount 0.995 --restore_path ../../scratch/gcfql/horizon-reduction/gcfql_maze_oracle4_8/sd000_1436627854958.s_27680618_2.20250829_185820_547.gcfql_maze_oracle4_8 --restore_epoch 2000000 --q_pred_calc batch --log_interval 10 --eval_interval 50'
 [10]='python3 train_value.py --run_group train_value2_1 --env_name humanoidmaze-medium-navigate-oraclerep-v0 --agent ../agents/gcfql.py --dataset_dir ../../scratch/data/humanoidmaze-medium-navigate-v0 --train_data_size 100000 --offline_steps 100 --save_interval 100 --save_dir ../../scratch/gcfql/ --agent.alpha 300 --agent.actor_type best-of-n --agent.train_goal_proposer=True --agent.actor_hidden_dims 512,512,512,512 --agent.value_hidden_dims 512,512,512,512 --agent.batch_size 256 --agent.num_actions 8 --agent.num_qs 2 --agent.subgoal_steps 50 --json_path ../jsons/data.json --agent.awr_invtemp 1.0 --agent.discount 0.995 --restore_path ../../scratch/gcfql/horizon-reduction/gcfql_maze_oracle4_8/sd000_1436627854958.s_27680618_2.20250829_185820_547.gcfql_maze_oracle4_8 --restore_epoch 2000000 --q_pred_calc sample --log_interval 10 --eval_interval 50'
 [11]='python3 train_value.py --run_group train_value2_1 --env_name humanoidmaze-medium-navigate-oraclerep-v0 --agent ../agents/gcfql.py --dataset_dir ../../scratch/data/humanoidmaze-medium-navigate-v0 --train_data_size 100000 --offline_steps 100 --save_interval 100 --save_dir ../../scratch/gcfql/ --agent.alpha 300 --agent.actor_type best-of-n --agent.train_goal_proposer=True --agent.actor_hidden_dims 512,512,512,512 --agent.value_hidden_dims 512,512,512,512 --agent.batch_size 256 --agent.num_actions 8 --agent.num_qs 2 --agent.subgoal_steps 50 --json_path ../jsons/data.json --agent.awr_invtemp 1.0 --agent.discount 0.995 --restore_path ../../scratch/gcfql/horizon-reduction/gcfql_maze_oracle4_8/sd000_1426623563374.s_27680619_3.20250829_185930_100.gcfql_maze_oracle4_8 --restore_epoch 2000000 --q_pred_calc batch --log_interval 10 --eval_interval 50'
 [12]='python3 train_value.py --run_group train_value2_1 --env_name humanoidmaze-medium-navigate-oraclerep-v0 --agent ../agents/gcfql.py --dataset_dir ../../scratch/data/humanoidmaze-medium-navigate-v0 --train_data_size 100000 --offline_steps 100 --save_interval 100 --save_dir ../../scratch/gcfql/ --agent.alpha 300 --agent.actor_type best-of-n --agent.train_goal_proposer=True --agent.actor_hidden_dims 512,512,512,512 --agent.value_hidden_dims 512,512,512,512 --agent.batch_size 256 --agent.num_actions 8 --agent.num_qs 2 --agent.subgoal_steps 50 --json_path ../jsons/data.json --agent.awr_invtemp 1.0 --agent.discount 0.995 --restore_path ../../scratch/gcfql/horizon-reduction/gcfql_maze_oracle4_8/sd000_1426623563374.s_27680619_3.20250829_185930_100.gcfql_maze_oracle4_8 --restore_epoch 2000000 --q_pred_calc sample --log_interval 10 --eval_interval 50'
 [13]='python3 train_value.py --run_group train_value2_1 --env_name humanoidmaze-medium-navigate-oraclerep-v0 --agent ../agents/gcfql.py --dataset_dir ../../scratch/data/humanoidmaze-medium-navigate-v0 --train_data_size 100000 --offline_steps 100 --save_interval 100 --save_dir ../../scratch/gcfql/ --agent.alpha 300 --agent.actor_type best-of-n --agent.train_goal_proposer=True --agent.actor_hidden_dims 512,512,512,512 --agent.value_hidden_dims 512,512,512,512 --agent.batch_size 256 --agent.num_actions 8 --agent.num_qs 2 --agent.subgoal_steps 50 --json_path ../jsons/data.json --agent.awr_invtemp 1.0 --agent.discount 0.995 --restore_path ../../scratch/gcfql/horizon-reduction/gcfql_maze_oracle4_8/sd000_1414600722027.s_27680590_6.20250829_185845_686.gcfql_maze_oracle4_8 --restore_epoch 2000000 --q_pred_calc batch --log_interval 10 --eval_interval 50'
 [14]='python3 train_value.py --run_group train_value2_1 --env_name humanoidmaze-medium-navigate-oraclerep-v0 --agent ../agents/gcfql.py --dataset_dir ../../scratch/data/humanoidmaze-medium-navigate-v0 --train_data_size 100000 --offline_steps 100 --save_interval 100 --save_dir ../../scratch/gcfql/ --agent.alpha 300 --agent.actor_type best-of-n --agent.train_goal_proposer=True --agent.actor_hidden_dims 512,512,512,512 --agent.value_hidden_dims 512,512,512,512 --agent.batch_size 256 --agent.num_actions 8 --agent.num_qs 2 --agent.subgoal_steps 50 --json_path ../jsons/data.json --agent.awr_invtemp 1.0 --agent.discount 0.995 --restore_path ../../scratch/gcfql/horizon-reduction/gcfql_maze_oracle4_8/sd000_1414600722027.s_27680590_6.20250829_185845_686.gcfql_maze_oracle4_8 --restore_epoch 2000000 --q_pred_calc sample --log_interval 10 --eval_interval 50'
 [15]='python3 train_value.py --run_group train_value2_1 --env_name humanoidmaze-medium-navigate-oraclerep-v0 --agent ../agents/gcfql.py --dataset_dir ../../scratch/data/humanoidmaze-medium-navigate-v0 --train_data_size 100000 --offline_steps 100 --save_interval 100 --save_dir ../../scratch/gcfql/ --agent.alpha 300 --agent.actor_type best-of-n --agent.train_goal_proposer=True --agent.actor_hidden_dims 512,512,512,512 --agent.value_hidden_dims 512,512,512,512 --agent.batch_size 256 --agent.num_actions 8 --agent.num_qs 2 --agent.subgoal_steps 50 --json_path ../jsons/data.json --agent.awr_invtemp 1.0 --agent.discount 0.995 --restore_path ../../scratch/gcfql/horizon-reduction/gcfql_maze_oracle4_8/sd000_1414321273454.s_27680627_5.20250829_185845_775.gcfql_maze_oracle4_8 --restore_epoch 2000000 --q_pred_calc batch --log_interval 10 --eval_interval 50'
 [16]='python3 train_value.py --run_group train_value2_1 --env_name humanoidmaze-medium-navigate-oraclerep-v0 --agent ../agents/gcfql.py --dataset_dir ../../scratch/data/humanoidmaze-medium-navigate-v0 --train_data_size 100000 --offline_steps 100 --save_interval 100 --save_dir ../../scratch/gcfql/ --agent.alpha 300 --agent.actor_type best-of-n --agent.train_goal_proposer=True --agent.actor_hidden_dims 512,512,512,512 --agent.value_hidden_dims 512,512,512,512 --agent.batch_size 256 --agent.num_actions 8 --agent.num_qs 2 --agent.subgoal_steps 50 --json_path ../jsons/data.json --agent.awr_invtemp 1.0 --agent.discount 0.995 --restore_path ../../scratch/gcfql/horizon-reduction/gcfql_maze_oracle4_8/sd000_1414321273454.s_27680627_5.20250829_185845_775.gcfql_maze_oracle4_8 --restore_epoch 2000000 --q_pred_calc sample --log_interval 10 --eval_interval 50'
 [17]='python3 train_value.py --run_group train_value2_1 --env_name humanoidmaze-medium-navigate-oraclerep-v0 --agent ../agents/gcfql.py --dataset_dir ../../scratch/data/humanoidmaze-medium-navigate-v0 --train_data_size 100000 --offline_steps 100 --save_interval 100 --save_dir ../../scratch/gcfql/ --agent.alpha 300 --agent.actor_type best-of-n --agent.train_goal_proposer=True --agent.actor_hidden_dims 512,512,512,512 --agent.value_hidden_dims 512,512,512,512 --agent.batch_size 256 --agent.num_actions 8 --agent.num_qs 2 --agent.subgoal_steps 50 --json_path ../jsons/data.json --agent.awr_invtemp 1.0 --agent.discount 0.995 --restore_path ../../scratch/gcfql/horizon-reduction/gcfql_maze_oracle4_8/sd000_1452282852974.s_27680618_2.20250829_185841_310.gcfql_maze_oracle4_8 --restore_epoch 2000000 --q_pred_calc batch --log_interval 10 --eval_interval 50'
 [18]='python3 train_value.py --run_group train_value2_1 --env_name humanoidmaze-medium-navigate-oraclerep-v0 --agent ../agents/gcfql.py --dataset_dir ../../scratch/data/humanoidmaze-medium-navigate-v0 --train_data_size 100000 --offline_steps 100 --save_interval 100 --save_dir ../../scratch/gcfql/ --agent.alpha 300 --agent.actor_type best-of-n --agent.train_goal_proposer=True --agent.actor_hidden_dims 512,512,512,512 --agent.value_hidden_dims 512,512,512,512 --agent.batch_size 256 --agent.num_actions 8 --agent.num_qs 2 --agent.subgoal_steps 50 --json_path ../jsons/data.json --agent.awr_invtemp 1.0 --agent.discount 0.995 --restore_path ../../scratch/gcfql/horizon-reduction/gcfql_maze_oracle4_8/sd000_1452282852974.s_27680618_2.20250829_185841_310.gcfql_maze_oracle4_8 --restore_epoch 2000000 --q_pred_calc sample --log_interval 10 --eval_interval 50'
 [19]='python3 train_value.py --run_group train_value2_1 --env_name humanoidmaze-medium-navigate-oraclerep-v0 --agent ../agents/gcfql.py --dataset_dir ../../scratch/data/humanoidmaze-medium-navigate-v0 --train_data_size 100000 --offline_steps 100 --save_interval 100 --save_dir ../../scratch/gcfql/ --agent.alpha 300 --agent.actor_type best-of-n --agent.train_goal_proposer=True --agent.actor_hidden_dims 512,512,512,512 --agent.value_hidden_dims 512,512,512,512 --agent.batch_size 256 --agent.num_actions 8 --agent.num_qs 2 --agent.subgoal_steps 50 --json_path ../jsons/data.json --agent.awr_invtemp 1.0 --agent.discount 0.995 --restore_path ../../scratch/gcfql/horizon-reduction/gcfql_maze_oracle4_8/sd000_1448103063147.s_27680617_1.20250829_190015_646.gcfql_maze_oracle4_8 --restore_epoch 2000000 --q_pred_calc batch --log_interval 10 --eval_interval 50'
 [20]='python3 train_value.py --run_group train_value2_1 --env_name humanoidmaze-medium-navigate-oraclerep-v0 --agent ../agents/gcfql.py --dataset_dir ../../scratch/data/humanoidmaze-medium-navigate-v0 --train_data_size 100000 --offline_steps 100 --save_interval 100 --save_dir ../../scratch/gcfql/ --agent.alpha 300 --agent.actor_type best-of-n --agent.train_goal_proposer=True --agent.actor_hidden_dims 512,512,512,512 --agent.value_hidden_dims 512,512,512,512 --agent.batch_size 256 --agent.num_actions 8 --agent.num_qs 2 --agent.subgoal_steps 50 --json_path ../jsons/data.json --agent.awr_invtemp 1.0 --agent.discount 0.995 --restore_path ../../scratch/gcfql/horizon-reduction/gcfql_maze_oracle4_8/sd000_1448103063147.s_27680617_1.20250829_190015_646.gcfql_maze_oracle4_8 --restore_epoch 2000000 --q_pred_calc sample --log_interval 10 --eval_interval 50'
 [21]='python3 train_value.py --run_group train_value2_1 --env_name humanoidmaze-medium-navigate-oraclerep-v0 --agent ../agents/gcfql.py --dataset_dir ../../scratch/data/humanoidmaze-medium-navigate-v0 --train_data_size 100000 --offline_steps 100 --save_interval 100 --save_dir ../../scratch/gcfql/ --agent.alpha 300 --agent.actor_type best-of-n --agent.train_goal_proposer=True --agent.actor_hidden_dims 512,512,512,512 --agent.value_hidden_dims 512,512,512,512 --agent.batch_size 256 --agent.num_actions 8 --agent.num_qs 2 --agent.subgoal_steps 50 --json_path ../jsons/data.json --agent.awr_invtemp 1.0 --agent.discount 0.995 --restore_path ../../scratch/gcfql/horizon-reduction/gcfql_maze_oracle4_8/sd000_1441449117294.s_27680626_4.20250829_185845_562.gcfql_maze_oracle4_8 --restore_epoch 2000000 --q_pred_calc batch --log_interval 10 --eval_interval 50'
 [22]='python3 train_value.py --run_group train_value2_1 --env_name humanoidmaze-medium-navigate-oraclerep-v0 --agent ../agents/gcfql.py --dataset_dir ../../scratch/data/humanoidmaze-medium-navigate-v0 --train_data_size 100000 --offline_steps 100 --save_interval 100 --save_dir ../../scratch/gcfql/ --agent.alpha 300 --agent.actor_type best-of-n --agent.train_goal_proposer=True --agent.actor_hidden_dims 512,512,512,512 --agent.value_hidden_dims 512,512,512,512 --agent.batch_size 256 --agent.num_actions 8 --agent.num_qs 2 --agent.subgoal_steps 50 --json_path ../jsons/data.json --agent.awr_invtemp 1.0 --agent.discount 0.995 --restore_path ../../scratch/gcfql/horizon-reduction/gcfql_maze_oracle4_8/sd000_1441449117294.s_27680626_4.20250829_185845_562.gcfql_maze_oracle4_8 --restore_epoch 2000000 --q_pred_calc sample --log_interval 10 --eval_interval 50'
 [23]='python3 train_value.py --run_group train_value2_1 --env_name humanoidmaze-medium-navigate-oraclerep-v0 --agent ../agents/gcfql.py --dataset_dir ../../scratch/data/humanoidmaze-medium-navigate-v0 --train_data_size 100000 --offline_steps 100 --save_interval 100 --save_dir ../../scratch/gcfql/ --agent.alpha 300 --agent.actor_type best-of-n --agent.train_goal_proposer=True --agent.actor_hidden_dims 512,512,512,512 --agent.value_hidden_dims 512,512,512,512 --agent.batch_size 256 --agent.num_actions 8 --agent.num_qs 2 --agent.subgoal_steps 50 --json_path ../jsons/data.json --agent.awr_invtemp 1.0 --agent.discount 0.995 --restore_path ../../scratch/gcfql/horizon-reduction/gcfql_maze_oracle4_8/sd000_1433843123822.s_27680627_5.20250829_185906_465.gcfql_maze_oracle4_8 --restore_epoch 2000000 --q_pred_calc batch --log_interval 10 --eval_interval 50'
 [24]='python3 train_value.py --run_group train_value2_1 --env_name humanoidmaze-medium-navigate-oraclerep-v0 --agent ../agents/gcfql.py --dataset_dir ../../scratch/data/humanoidmaze-medium-navigate-v0 --train_data_size 100000 --offline_steps 100 --save_interval 100 --save_dir ../../scratch/gcfql/ --agent.alpha 300 --agent.actor_type best-of-n --agent.train_goal_proposer=True --agent.actor_hidden_dims 512,512,512,512 --agent.value_hidden_dims 512,512,512,512 --agent.batch_size 256 --agent.num_actions 8 --agent.num_qs 2 --agent.subgoal_steps 50 --json_path ../jsons/data.json --agent.awr_invtemp 1.0 --agent.discount 0.995 --restore_path ../../scratch/gcfql/horizon-reduction/gcfql_maze_oracle4_8/sd000_1433843123822.s_27680627_5.20250829_185906_465.gcfql_maze_oracle4_8 --restore_epoch 2000000 --q_pred_calc sample --log_interval 10 --eval_interval 50'
 [25]='python3 train_value.py --run_group train_value2_1 --env_name humanoidmaze-medium-navigate-oraclerep-v0 --agent ../agents/gcfql.py --dataset_dir ../../scratch/data/humanoidmaze-medium-navigate-v0 --train_data_size 100000 --offline_steps 100 --save_interval 100 --save_dir ../../scratch/gcfql/ --agent.alpha 300 --agent.actor_type best-of-n --agent.train_goal_proposer=True --agent.actor_hidden_dims 512,512,512,512 --agent.value_hidden_dims 512,512,512,512 --agent.batch_size 256 --agent.num_actions 8 --agent.num_qs 2 --agent.subgoal_steps 100 --json_path ../jsons/data.json --agent.awr_invtemp 1.0 --agent.discount 0.995 --restore_path ../../scratch/gcfql/horizon-reduction/gcfql_maze_oracle4_8/sd000_1456162036334.s_27680590_6.20250829_185905_857.gcfql_maze_oracle4_8 --restore_epoch 2000000 --q_pred_calc batch --log_interval 10 --eval_interval 50'
 [26]='python3 train_value.py --run_group train_value2_1 --env_name humanoidmaze-medium-navigate-oraclerep-v0 --agent ../agents/gcfql.py --dataset_dir ../../scratch/data/humanoidmaze-medium-navigate-v0 --train_data_size 100000 --offline_steps 100 --save_interval 100 --save_dir ../../scratch/gcfql/ --agent.alpha 300 --agent.actor_type best-of-n --agent.train_goal_proposer=True --agent.actor_hidden_dims 512,512,512,512 --agent.value_hidden_dims 512,512,512,512 --agent.batch_size 256 --agent.num_actions 8 --agent.num_qs 2 --agent.subgoal_steps 100 --json_path ../jsons/data.json --agent.awr_invtemp 1.0 --agent.discount 0.995 --restore_path ../../scratch/gcfql/horizon-reduction/gcfql_maze_oracle4_8/sd000_1456162036334.s_27680590_6.20250829_185905_857.gcfql_maze_oracle4_8 --restore_epoch 2000000 --q_pred_calc sample --log_interval 10 --eval_interval 50'
 [27]='python3 train_value.py --run_group train_value2_1 --env_name humanoidmaze-medium-navigate-oraclerep-v0 --agent ../agents/gcfql.py --dataset_dir ../../scratch/data/humanoidmaze-medium-navigate-v0 --train_data_size 100000 --offline_steps 100 --save_interval 100 --save_dir ../../scratch/gcfql/ --agent.alpha 300 --agent.actor_type best-of-n --agent.train_goal_proposer=True --agent.actor_hidden_dims 512,512,512,512 --agent.value_hidden_dims 512,512,512,512 --agent.batch_size 256 --agent.num_actions 8 --agent.num_qs 2 --agent.subgoal_steps 100 --json_path ../jsons/data.json --agent.awr_invtemp 1.0 --agent.discount 0.995 --restore_path ../../scratch/gcfql/horizon-reduction/gcfql_maze_oracle4_8/sd000_1453467320942.s_27680626_4.20250829_185906_336.gcfql_maze_oracle4_8 --restore_epoch 2000000 --q_pred_calc batch --log_interval 10 --eval_interval 50'
 [28]='python3 train_value.py --run_group train_value2_1 --env_name humanoidmaze-medium-navigate-oraclerep-v0 --agent ../agents/gcfql.py --dataset_dir ../../scratch/data/humanoidmaze-medium-navigate-v0 --train_data_size 100000 --offline_steps 100 --save_interval 100 --save_dir ../../scratch/gcfql/ --agent.alpha 300 --agent.actor_type best-of-n --agent.train_goal_proposer=True --agent.actor_hidden_dims 512,512,512,512 --agent.value_hidden_dims 512,512,512,512 --agent.batch_size 256 --agent.num_actions 8 --agent.num_qs 2 --agent.subgoal_steps 100 --json_path ../jsons/data.json --agent.awr_invtemp 1.0 --agent.discount 0.995 --restore_path ../../scratch/gcfql/horizon-reduction/gcfql_maze_oracle4_8/sd000_1453467320942.s_27680626_4.20250829_185906_336.gcfql_maze_oracle4_8 --restore_epoch 2000000 --q_pred_calc sample --log_interval 10 --eval_interval 50'
 [29]='python3 train_value.py --run_group train_value2_1 --env_name humanoidmaze-medium-navigate-oraclerep-v0 --agent ../agents/gcfql.py --dataset_dir ../../scratch/data/humanoidmaze-medium-navigate-v0 --train_data_size 100000 --offline_steps 100 --save_interval 100 --save_dir ../../scratch/gcfql/ --agent.alpha 300 --agent.actor_type best-of-n --agent.train_goal_proposer=True --agent.actor_hidden_dims 512,512,512,512 --agent.value_hidden_dims 512,512,512,512 --agent.batch_size 256 --agent.num_actions 8 --agent.num_qs 2 --agent.subgoal_steps 100 --json_path ../jsons/data.json --agent.awr_invtemp 1.0 --agent.discount 0.995 --restore_path ../../scratch/gcfql/horizon-reduction/gcfql_maze_oracle4_8/sd000_1448342040171.s_27680619_3.20250829_185930_100.gcfql_maze_oracle4_8 --restore_epoch 2000000 --q_pred_calc batch --log_interval 10 --eval_interval 50'
 [30]='python3 train_value.py --run_group train_value2_1 --env_name humanoidmaze-medium-navigate-oraclerep-v0 --agent ../agents/gcfql.py --dataset_dir ../../scratch/data/humanoidmaze-medium-navigate-v0 --train_data_size 100000 --offline_steps 100 --save_interval 100 --save_dir ../../scratch/gcfql/ --agent.alpha 300 --agent.actor_type best-of-n --agent.train_goal_proposer=True --agent.actor_hidden_dims 512,512,512,512 --agent.value_hidden_dims 512,512,512,512 --agent.batch_size 256 --agent.num_actions 8 --agent.num_qs 2 --agent.subgoal_steps 100 --json_path ../jsons/data.json --agent.awr_invtemp 1.0 --agent.discount 0.995 --restore_path ../../scratch/gcfql/horizon-reduction/gcfql_maze_oracle4_8/sd000_1448342040171.s_27680619_3.20250829_185930_100.gcfql_maze_oracle4_8 --restore_epoch 2000000 --q_pred_calc sample --log_interval 10 --eval_interval 50'
 [31]='python3 train_value.py --run_group train_value2_1 --env_name humanoidmaze-medium-navigate-oraclerep-v0 --agent ../agents/gcfql.py --dataset_dir ../../scratch/data/humanoidmaze-medium-navigate-v0 --train_data_size 100000 --offline_steps 100 --save_interval 100 --save_dir ../../scratch/gcfql/ --agent.alpha 300 --agent.actor_type best-of-n --agent.train_goal_proposer=True --agent.actor_hidden_dims 512,512,512,512 --agent.value_hidden_dims 512,512,512,512 --agent.batch_size 256 --agent.num_actions 8 --agent.num_qs 2 --agent.subgoal_steps 100 --json_path ../jsons/data.json --agent.awr_invtemp 1.0 --agent.discount 0.995 --restore_path ../../scratch/gcfql/horizon-reduction/gcfql_maze_oracle4_8/sd000_1438812371566.s_27680617_1.20250829_190015_646.gcfql_maze_oracle4_8 --restore_epoch 2000000 --q_pred_calc batch --log_interval 10 --eval_interval 50'
 [32]='python3 train_value.py --run_group train_value2_1 --env_name humanoidmaze-medium-navigate-oraclerep-v0 --agent ../agents/gcfql.py --dataset_dir ../../scratch/data/humanoidmaze-medium-navigate-v0 --train_data_size 100000 --offline_steps 100 --save_interval 100 --save_dir ../../scratch/gcfql/ --agent.alpha 300 --agent.actor_type best-of-n --agent.train_goal_proposer=True --agent.actor_hidden_dims 512,512,512,512 --agent.value_hidden_dims 512,512,512,512 --agent.batch_size 256 --agent.num_actions 8 --agent.num_qs 2 --agent.subgoal_steps 100 --json_path ../jsons/data.json --agent.awr_invtemp 1.0 --agent.discount 0.995 --restore_path ../../scratch/gcfql/horizon-reduction/gcfql_maze_oracle4_8/sd000_1438812371566.s_27680617_1.20250829_190015_646.gcfql_maze_oracle4_8 --restore_epoch 2000000 --q_pred_calc sample --log_interval 10 --eval_interval 50'
 [33]='python3 train_value.py --run_group train_value2_1 --env_name humanoidmaze-medium-navigate-oraclerep-v0 --agent ../agents/gcfql.py --dataset_dir ../../scratch/data/humanoidmaze-medium-navigate-v0 --train_data_size 100000 --offline_steps 100 --save_interval 100 --save_dir ../../scratch/gcfql/ --agent.alpha 300 --agent.actor_type best-of-n --agent.train_goal_proposer=True --agent.actor_hidden_dims 512,512,512,512 --agent.value_hidden_dims 512,512,512,512 --agent.batch_size 256 --agent.num_actions 8 --agent.num_qs 2 --agent.subgoal_steps 100 --json_path ../jsons/data.json --agent.awr_invtemp 1.0 --agent.discount 0.995 --restore_path ../../scratch/gcfql/horizon-reduction/gcfql_maze_oracle4_8/sd000_1436627854958.s_27680618_2.20250829_185820_547.gcfql_maze_oracle4_8 --restore_epoch 2000000 --q_pred_calc batch --log_interval 10 --eval_interval 50'
 [34]='python3 train_value.py --run_group train_value2_1 --env_name humanoidmaze-medium-navigate-oraclerep-v0 --agent ../agents/gcfql.py --dataset_dir ../../scratch/data/humanoidmaze-medium-navigate-v0 --train_data_size 100000 --offline_steps 100 --save_interval 100 --save_dir ../../scratch/gcfql/ --agent.alpha 300 --agent.actor_type best-of-n --agent.train_goal_proposer=True --agent.actor_hidden_dims 512,512,512,512 --agent.value_hidden_dims 512,512,512,512 --agent.batch_size 256 --agent.num_actions 8 --agent.num_qs 2 --agent.subgoal_steps 100 --json_path ../jsons/data.json --agent.awr_invtemp 1.0 --agent.discount 0.995 --restore_path ../../scratch/gcfql/horizon-reduction/gcfql_maze_oracle4_8/sd000_1436627854958.s_27680618_2.20250829_185820_547.gcfql_maze_oracle4_8 --restore_epoch 2000000 --q_pred_calc sample --log_interval 10 --eval_interval 50'
 [35]='python3 train_value.py --run_group train_value2_1 --env_name humanoidmaze-medium-navigate-oraclerep-v0 --agent ../agents/gcfql.py --dataset_dir ../../scratch/data/humanoidmaze-medium-navigate-v0 --train_data_size 100000 --offline_steps 100 --save_interval 100 --save_dir ../../scratch/gcfql/ --agent.alpha 300 --agent.actor_type best-of-n --agent.train_goal_proposer=True --agent.actor_hidden_dims 512,512,512,512 --agent.value_hidden_dims 512,512,512,512 --agent.batch_size 256 --agent.num_actions 8 --agent.num_qs 2 --agent.subgoal_steps 100 --json_path ../jsons/data.json --agent.awr_invtemp 1.0 --agent.discount 0.995 --restore_path ../../scratch/gcfql/horizon-reduction/gcfql_maze_oracle4_8/sd000_1426623563374.s_27680619_3.20250829_185930_100.gcfql_maze_oracle4_8 --restore_epoch 2000000 --q_pred_calc batch --log_interval 10 --eval_interval 50'
 [36]='python3 train_value.py --run_group train_value2_1 --env_name humanoidmaze-medium-navigate-oraclerep-v0 --agent ../agents/gcfql.py --dataset_dir ../../scratch/data/humanoidmaze-medium-navigate-v0 --train_data_size 100000 --offline_steps 100 --save_interval 100 --save_dir ../../scratch/gcfql/ --agent.alpha 300 --agent.actor_type best-of-n --agent.train_goal_proposer=True --agent.actor_hidden_dims 512,512,512,512 --agent.value_hidden_dims 512,512,512,512 --agent.batch_size 256 --agent.num_actions 8 --agent.num_qs 2 --agent.subgoal_steps 100 --json_path ../jsons/data.json --agent.awr_invtemp 1.0 --agent.discount 0.995 --restore_path ../../scratch/gcfql/horizon-reduction/gcfql_maze_oracle4_8/sd000_1426623563374.s_27680619_3.20250829_185930_100.gcfql_maze_oracle4_8 --restore_epoch 2000000 --q_pred_calc sample --log_interval 10 --eval_interval 50'
 [37]='python3 train_value.py --run_group train_value2_1 --env_name humanoidmaze-medium-navigate-oraclerep-v0 --agent ../agents/gcfql.py --dataset_dir ../../scratch/data/humanoidmaze-medium-navigate-v0 --train_data_size 100000 --offline_steps 100 --save_interval 100 --save_dir ../../scratch/gcfql/ --agent.alpha 300 --agent.actor_type best-of-n --agent.train_goal_proposer=True --agent.actor_hidden_dims 512,512,512,512 --agent.value_hidden_dims 512,512,512,512 --agent.batch_size 256 --agent.num_actions 8 --agent.num_qs 2 --agent.subgoal_steps 100 --json_path ../jsons/data.json --agent.awr_invtemp 1.0 --agent.discount 0.995 --restore_path ../../scratch/gcfql/horizon-reduction/gcfql_maze_oracle4_8/sd000_1414600722027.s_27680590_6.20250829_185845_686.gcfql_maze_oracle4_8 --restore_epoch 2000000 --q_pred_calc batch --log_interval 10 --eval_interval 50'
 [38]='python3 train_value.py --run_group train_value2_1 --env_name humanoidmaze-medium-navigate-oraclerep-v0 --agent ../agents/gcfql.py --dataset_dir ../../scratch/data/humanoidmaze-medium-navigate-v0 --train_data_size 100000 --offline_steps 100 --save_interval 100 --save_dir ../../scratch/gcfql/ --agent.alpha 300 --agent.actor_type best-of-n --agent.train_goal_proposer=True --agent.actor_hidden_dims 512,512,512,512 --agent.value_hidden_dims 512,512,512,512 --agent.batch_size 256 --agent.num_actions 8 --agent.num_qs 2 --agent.subgoal_steps 100 --json_path ../jsons/data.json --agent.awr_invtemp 1.0 --agent.discount 0.995 --restore_path ../../scratch/gcfql/horizon-reduction/gcfql_maze_oracle4_8/sd000_1414600722027.s_27680590_6.20250829_185845_686.gcfql_maze_oracle4_8 --restore_epoch 2000000 --q_pred_calc sample --log_interval 10 --eval_interval 50'
 [39]='python3 train_value.py --run_group train_value2_1 --env_name humanoidmaze-medium-navigate-oraclerep-v0 --agent ../agents/gcfql.py --dataset_dir ../../scratch/data/humanoidmaze-medium-navigate-v0 --train_data_size 100000 --offline_steps 100 --save_interval 100 --save_dir ../../scratch/gcfql/ --agent.alpha 300 --agent.actor_type best-of-n --agent.train_goal_proposer=True --agent.actor_hidden_dims 512,512,512,512 --agent.value_hidden_dims 512,512,512,512 --agent.batch_size 256 --agent.num_actions 8 --agent.num_qs 2 --agent.subgoal_steps 100 --json_path ../jsons/data.json --agent.awr_invtemp 1.0 --agent.discount 0.995 --restore_path ../../scratch/gcfql/horizon-reduction/gcfql_maze_oracle4_8/sd000_1414321273454.s_27680627_5.20250829_185845_775.gcfql_maze_oracle4_8 --restore_epoch 2000000 --q_pred_calc batch --log_interval 10 --eval_interval 50'
 [40]='python3 train_value.py --run_group train_value2_1 --env_name humanoidmaze-medium-navigate-oraclerep-v0 --agent ../agents/gcfql.py --dataset_dir ../../scratch/data/humanoidmaze-medium-navigate-v0 --train_data_size 100000 --offline_steps 100 --save_interval 100 --save_dir ../../scratch/gcfql/ --agent.alpha 300 --agent.actor_type best-of-n --agent.train_goal_proposer=True --agent.actor_hidden_dims 512,512,512,512 --agent.value_hidden_dims 512,512,512,512 --agent.batch_size 256 --agent.num_actions 8 --agent.num_qs 2 --agent.subgoal_steps 100 --json_path ../jsons/data.json --agent.awr_invtemp 1.0 --agent.discount 0.995 --restore_path ../../scratch/gcfql/horizon-reduction/gcfql_maze_oracle4_8/sd000_1414321273454.s_27680627_5.20250829_185845_775.gcfql_maze_oracle4_8 --restore_epoch 2000000 --q_pred_calc sample --log_interval 10 --eval_interval 50'
 [41]='python3 train_value.py --run_group train_value2_1 --env_name humanoidmaze-medium-navigate-oraclerep-v0 --agent ../agents/gcfql.py --dataset_dir ../../scratch/data/humanoidmaze-medium-navigate-v0 --train_data_size 100000 --offline_steps 100 --save_interval 100 --save_dir ../../scratch/gcfql/ --agent.alpha 300 --agent.actor_type best-of-n --agent.train_goal_proposer=True --agent.actor_hidden_dims 512,512,512,512 --agent.value_hidden_dims 512,512,512,512 --agent.batch_size 256 --agent.num_actions 8 --agent.num_qs 2 --agent.subgoal_steps 100 --json_path ../jsons/data.json --agent.awr_invtemp 1.0 --agent.discount 0.995 --restore_path ../../scratch/gcfql/horizon-reduction/gcfql_maze_oracle4_8/sd000_1452282852974.s_27680618_2.20250829_185841_310.gcfql_maze_oracle4_8 --restore_epoch 2000000 --q_pred_calc batch --log_interval 10 --eval_interval 50'
 [42]='python3 train_value.py --run_group train_value2_1 --env_name humanoidmaze-medium-navigate-oraclerep-v0 --agent ../agents/gcfql.py --dataset_dir ../../scratch/data/humanoidmaze-medium-navigate-v0 --train_data_size 100000 --offline_steps 100 --save_interval 100 --save_dir ../../scratch/gcfql/ --agent.alpha 300 --agent.actor_type best-of-n --agent.train_goal_proposer=True --agent.actor_hidden_dims 512,512,512,512 --agent.value_hidden_dims 512,512,512,512 --agent.batch_size 256 --agent.num_actions 8 --agent.num_qs 2 --agent.subgoal_steps 100 --json_path ../jsons/data.json --agent.awr_invtemp 1.0 --agent.discount 0.995 --restore_path ../../scratch/gcfql/horizon-reduction/gcfql_maze_oracle4_8/sd000_1452282852974.s_27680618_2.20250829_185841_310.gcfql_maze_oracle4_8 --restore_epoch 2000000 --q_pred_calc sample --log_interval 10 --eval_interval 50'
 [43]='python3 train_value.py --run_group train_value2_1 --env_name humanoidmaze-medium-navigate-oraclerep-v0 --agent ../agents/gcfql.py --dataset_dir ../../scratch/data/humanoidmaze-medium-navigate-v0 --train_data_size 100000 --offline_steps 100 --save_interval 100 --save_dir ../../scratch/gcfql/ --agent.alpha 300 --agent.actor_type best-of-n --agent.train_goal_proposer=True --agent.actor_hidden_dims 512,512,512,512 --agent.value_hidden_dims 512,512,512,512 --agent.batch_size 256 --agent.num_actions 8 --agent.num_qs 2 --agent.subgoal_steps 100 --json_path ../jsons/data.json --agent.awr_invtemp 1.0 --agent.discount 0.995 --restore_path ../../scratch/gcfql/horizon-reduction/gcfql_maze_oracle4_8/sd000_1448103063147.s_27680617_1.20250829_190015_646.gcfql_maze_oracle4_8 --restore_epoch 2000000 --q_pred_calc batch --log_interval 10 --eval_interval 50'
 [44]='python3 train_value.py --run_group train_value2_1 --env_name humanoidmaze-medium-navigate-oraclerep-v0 --agent ../agents/gcfql.py --dataset_dir ../../scratch/data/humanoidmaze-medium-navigate-v0 --train_data_size 100000 --offline_steps 100 --save_interval 100 --save_dir ../../scratch/gcfql/ --agent.alpha 300 --agent.actor_type best-of-n --agent.train_goal_proposer=True --agent.actor_hidden_dims 512,512,512,512 --agent.value_hidden_dims 512,512,512,512 --agent.batch_size 256 --agent.num_actions 8 --agent.num_qs 2 --agent.subgoal_steps 100 --json_path ../jsons/data.json --agent.awr_invtemp 1.0 --agent.discount 0.995 --restore_path ../../scratch/gcfql/horizon-reduction/gcfql_maze_oracle4_8/sd000_1448103063147.s_27680617_1.20250829_190015_646.gcfql_maze_oracle4_8 --restore_epoch 2000000 --q_pred_calc sample --log_interval 10 --eval_interval 50'
 [45]='python3 train_value.py --run_group train_value2_1 --env_name humanoidmaze-medium-navigate-oraclerep-v0 --agent ../agents/gcfql.py --dataset_dir ../../scratch/data/humanoidmaze-medium-navigate-v0 --train_data_size 100000 --offline_steps 100 --save_interval 100 --save_dir ../../scratch/gcfql/ --agent.alpha 300 --agent.actor_type best-of-n --agent.train_goal_proposer=True --agent.actor_hidden_dims 512,512,512,512 --agent.value_hidden_dims 512,512,512,512 --agent.batch_size 256 --agent.num_actions 8 --agent.num_qs 2 --agent.subgoal_steps 100 --json_path ../jsons/data.json --agent.awr_invtemp 1.0 --agent.discount 0.995 --restore_path ../../scratch/gcfql/horizon-reduction/gcfql_maze_oracle4_8/sd000_1441449117294.s_27680626_4.20250829_185845_562.gcfql_maze_oracle4_8 --restore_epoch 2000000 --q_pred_calc batch --log_interval 10 --eval_interval 50'
 [46]='python3 train_value.py --run_group train_value2_1 --env_name humanoidmaze-medium-navigate-oraclerep-v0 --agent ../agents/gcfql.py --dataset_dir ../../scratch/data/humanoidmaze-medium-navigate-v0 --train_data_size 100000 --offline_steps 100 --save_interval 100 --save_dir ../../scratch/gcfql/ --agent.alpha 300 --agent.actor_type best-of-n --agent.train_goal_proposer=True --agent.actor_hidden_dims 512,512,512,512 --agent.value_hidden_dims 512,512,512,512 --agent.batch_size 256 --agent.num_actions 8 --agent.num_qs 2 --agent.subgoal_steps 100 --json_path ../jsons/data.json --agent.awr_invtemp 1.0 --agent.discount 0.995 --restore_path ../../scratch/gcfql/horizon-reduction/gcfql_maze_oracle4_8/sd000_1441449117294.s_27680626_4.20250829_185845_562.gcfql_maze_oracle4_8 --restore_epoch 2000000 --q_pred_calc sample --log_interval 10 --eval_interval 50'
 [47]='python3 train_value.py --run_group train_value2_1 --env_name humanoidmaze-medium-navigate-oraclerep-v0 --agent ../agents/gcfql.py --dataset_dir ../../scratch/data/humanoidmaze-medium-navigate-v0 --train_data_size 100000 --offline_steps 100 --save_interval 100 --save_dir ../../scratch/gcfql/ --agent.alpha 300 --agent.actor_type best-of-n --agent.train_goal_proposer=True --agent.actor_hidden_dims 512,512,512,512 --agent.value_hidden_dims 512,512,512,512 --agent.batch_size 256 --agent.num_actions 8 --agent.num_qs 2 --agent.subgoal_steps 100 --json_path ../jsons/data.json --agent.awr_invtemp 1.0 --agent.discount 0.995 --restore_path ../../scratch/gcfql/horizon-reduction/gcfql_maze_oracle4_8/sd000_1433843123822.s_27680627_5.20250829_185906_465.gcfql_maze_oracle4_8 --restore_epoch 2000000 --q_pred_calc batch --log_interval 10 --eval_interval 50'
 [48]='python3 train_value.py --run_group train_value2_1 --env_name humanoidmaze-medium-navigate-oraclerep-v0 --agent ../agents/gcfql.py --dataset_dir ../../scratch/data/humanoidmaze-medium-navigate-v0 --train_data_size 100000 --offline_steps 100 --save_interval 100 --save_dir ../../scratch/gcfql/ --agent.alpha 300 --agent.actor_type best-of-n --agent.train_goal_proposer=True --agent.actor_hidden_dims 512,512,512,512 --agent.value_hidden_dims 512,512,512,512 --agent.batch_size 256 --agent.num_actions 8 --agent.num_qs 2 --agent.subgoal_steps 100 --json_path ../jsons/data.json --agent.awr_invtemp 1.0 --agent.discount 0.995 --restore_path ../../scratch/gcfql/horizon-reduction/gcfql_maze_oracle4_8/sd000_1433843123822.s_27680627_5.20250829_185906_465.gcfql_maze_oracle4_8 --restore_epoch 2000000 --q_pred_calc sample --log_interval 10 --eval_interval 50'
 [49]='python3 train_value.py --run_group train_value2_1 --env_name humanoidmaze-medium-navigate-oraclerep-v0 --agent ../agents/gcfql.py --dataset_dir ../../scratch/data/humanoidmaze-medium-navigate-v0 --train_data_size 1000000 --offline_steps 100 --save_interval 100 --save_dir ../../scratch/gcfql/ --agent.alpha 300 --agent.actor_type best-of-n --agent.train_goal_proposer=True --agent.actor_hidden_dims 512,512,512,512 --agent.value_hidden_dims 512,512,512,512 --agent.batch_size 256 --agent.num_actions 8 --agent.num_qs 2 --agent.subgoal_steps 50 --json_path ../jsons/data.json --agent.awr_invtemp 1.0 --agent.discount 0.995 --restore_path ../../scratch/gcfql/horizon-reduction/gcfql_maze_oracle4_8/sd000_1456162036334.s_27680590_6.20250829_185905_857.gcfql_maze_oracle4_8 --restore_epoch 2000000 --q_pred_calc batch --log_interval 10 --eval_interval 50'
 [50]='python3 train_value.py --run_group train_value2_1 --env_name humanoidmaze-medium-navigate-oraclerep-v0 --agent ../agents/gcfql.py --dataset_dir ../../scratch/data/humanoidmaze-medium-navigate-v0 --train_data_size 1000000 --offline_steps 100 --save_interval 100 --save_dir ../../scratch/gcfql/ --agent.alpha 300 --agent.actor_type best-of-n --agent.train_goal_proposer=True --agent.actor_hidden_dims 512,512,512,512 --agent.value_hidden_dims 512,512,512,512 --agent.batch_size 256 --agent.num_actions 8 --agent.num_qs 2 --agent.subgoal_steps 50 --json_path ../jsons/data.json --agent.awr_invtemp 1.0 --agent.discount 0.995 --restore_path ../../scratch/gcfql/horizon-reduction/gcfql_maze_oracle4_8/sd000_1456162036334.s_27680590_6.20250829_185905_857.gcfql_maze_oracle4_8 --restore_epoch 2000000 --q_pred_calc sample --log_interval 10 --eval_interval 50'
 [51]='python3 train_value.py --run_group train_value2_1 --env_name humanoidmaze-medium-navigate-oraclerep-v0 --agent ../agents/gcfql.py --dataset_dir ../../scratch/data/humanoidmaze-medium-navigate-v0 --train_data_size 1000000 --offline_steps 100 --save_interval 100 --save_dir ../../scratch/gcfql/ --agent.alpha 300 --agent.actor_type best-of-n --agent.train_goal_proposer=True --agent.actor_hidden_dims 512,512,512,512 --agent.value_hidden_dims 512,512,512,512 --agent.batch_size 256 --agent.num_actions 8 --agent.num_qs 2 --agent.subgoal_steps 50 --json_path ../jsons/data.json --agent.awr_invtemp 1.0 --agent.discount 0.995 --restore_path ../../scratch/gcfql/horizon-reduction/gcfql_maze_oracle4_8/sd000_1453467320942.s_27680626_4.20250829_185906_336.gcfql_maze_oracle4_8 --restore_epoch 2000000 --q_pred_calc batch --log_interval 10 --eval_interval 50'
 [52]='python3 train_value.py --run_group train_value2_1 --env_name humanoidmaze-medium-navigate-oraclerep-v0 --agent ../agents/gcfql.py --dataset_dir ../../scratch/data/humanoidmaze-medium-navigate-v0 --train_data_size 1000000 --offline_steps 100 --save_interval 100 --save_dir ../../scratch/gcfql/ --agent.alpha 300 --agent.actor_type best-of-n --agent.train_goal_proposer=True --agent.actor_hidden_dims 512,512,512,512 --agent.value_hidden_dims 512,512,512,512 --agent.batch_size 256 --agent.num_actions 8 --agent.num_qs 2 --agent.subgoal_steps 50 --json_path ../jsons/data.json --agent.awr_invtemp 1.0 --agent.discount 0.995 --restore_path ../../scratch/gcfql/horizon-reduction/gcfql_maze_oracle4_8/sd000_1453467320942.s_27680626_4.20250829_185906_336.gcfql_maze_oracle4_8 --restore_epoch 2000000 --q_pred_calc sample --log_interval 10 --eval_interval 50'
 [53]='python3 train_value.py --run_group train_value2_1 --env_name humanoidmaze-medium-navigate-oraclerep-v0 --agent ../agents/gcfql.py --dataset_dir ../../scratch/data/humanoidmaze-medium-navigate-v0 --train_data_size 1000000 --offline_steps 100 --save_interval 100 --save_dir ../../scratch/gcfql/ --agent.alpha 300 --agent.actor_type best-of-n --agent.train_goal_proposer=True --agent.actor_hidden_dims 512,512,512,512 --agent.value_hidden_dims 512,512,512,512 --agent.batch_size 256 --agent.num_actions 8 --agent.num_qs 2 --agent.subgoal_steps 50 --json_path ../jsons/data.json --agent.awr_invtemp 1.0 --agent.discount 0.995 --restore_path ../../scratch/gcfql/horizon-reduction/gcfql_maze_oracle4_8/sd000_1448342040171.s_27680619_3.20250829_185930_100.gcfql_maze_oracle4_8 --restore_epoch 2000000 --q_pred_calc batch --log_interval 10 --eval_interval 50'
 [54]='python3 train_value.py --run_group train_value2_1 --env_name humanoidmaze-medium-navigate-oraclerep-v0 --agent ../agents/gcfql.py --dataset_dir ../../scratch/data/humanoidmaze-medium-navigate-v0 --train_data_size 1000000 --offline_steps 100 --save_interval 100 --save_dir ../../scratch/gcfql/ --agent.alpha 300 --agent.actor_type best-of-n --agent.train_goal_proposer=True --agent.actor_hidden_dims 512,512,512,512 --agent.value_hidden_dims 512,512,512,512 --agent.batch_size 256 --agent.num_actions 8 --agent.num_qs 2 --agent.subgoal_steps 50 --json_path ../jsons/data.json --agent.awr_invtemp 1.0 --agent.discount 0.995 --restore_path ../../scratch/gcfql/horizon-reduction/gcfql_maze_oracle4_8/sd000_1448342040171.s_27680619_3.20250829_185930_100.gcfql_maze_oracle4_8 --restore_epoch 2000000 --q_pred_calc sample --log_interval 10 --eval_interval 50'
 [55]='python3 train_value.py --run_group train_value2_1 --env_name humanoidmaze-medium-navigate-oraclerep-v0 --agent ../agents/gcfql.py --dataset_dir ../../scratch/data/humanoidmaze-medium-navigate-v0 --train_data_size 1000000 --offline_steps 100 --save_interval 100 --save_dir ../../scratch/gcfql/ --agent.alpha 300 --agent.actor_type best-of-n --agent.train_goal_proposer=True --agent.actor_hidden_dims 512,512,512,512 --agent.value_hidden_dims 512,512,512,512 --agent.batch_size 256 --agent.num_actions 8 --agent.num_qs 2 --agent.subgoal_steps 50 --json_path ../jsons/data.json --agent.awr_invtemp 1.0 --agent.discount 0.995 --restore_path ../../scratch/gcfql/horizon-reduction/gcfql_maze_oracle4_8/sd000_1438812371566.s_27680617_1.20250829_190015_646.gcfql_maze_oracle4_8 --restore_epoch 2000000 --q_pred_calc batch --log_interval 10 --eval_interval 50'
 [56]='python3 train_value.py --run_group train_value2_1 --env_name humanoidmaze-medium-navigate-oraclerep-v0 --agent ../agents/gcfql.py --dataset_dir ../../scratch/data/humanoidmaze-medium-navigate-v0 --train_data_size 1000000 --offline_steps 100 --save_interval 100 --save_dir ../../scratch/gcfql/ --agent.alpha 300 --agent.actor_type best-of-n --agent.train_goal_proposer=True --agent.actor_hidden_dims 512,512,512,512 --agent.value_hidden_dims 512,512,512,512 --agent.batch_size 256 --agent.num_actions 8 --agent.num_qs 2 --agent.subgoal_steps 50 --json_path ../jsons/data.json --agent.awr_invtemp 1.0 --agent.discount 0.995 --restore_path ../../scratch/gcfql/horizon-reduction/gcfql_maze_oracle4_8/sd000_1438812371566.s_27680617_1.20250829_190015_646.gcfql_maze_oracle4_8 --restore_epoch 2000000 --q_pred_calc sample --log_interval 10 --eval_interval 50'
 [57]='python3 train_value.py --run_group train_value2_1 --env_name humanoidmaze-medium-navigate-oraclerep-v0 --agent ../agents/gcfql.py --dataset_dir ../../scratch/data/humanoidmaze-medium-navigate-v0 --train_data_size 1000000 --offline_steps 100 --save_interval 100 --save_dir ../../scratch/gcfql/ --agent.alpha 300 --agent.actor_type best-of-n --agent.train_goal_proposer=True --agent.actor_hidden_dims 512,512,512,512 --agent.value_hidden_dims 512,512,512,512 --agent.batch_size 256 --agent.num_actions 8 --agent.num_qs 2 --agent.subgoal_steps 50 --json_path ../jsons/data.json --agent.awr_invtemp 1.0 --agent.discount 0.995 --restore_path ../../scratch/gcfql/horizon-reduction/gcfql_maze_oracle4_8/sd000_1436627854958.s_27680618_2.20250829_185820_547.gcfql_maze_oracle4_8 --restore_epoch 2000000 --q_pred_calc batch --log_interval 10 --eval_interval 50'
 [58]='python3 train_value.py --run_group train_value2_1 --env_name humanoidmaze-medium-navigate-oraclerep-v0 --agent ../agents/gcfql.py --dataset_dir ../../scratch/data/humanoidmaze-medium-navigate-v0 --train_data_size 1000000 --offline_steps 100 --save_interval 100 --save_dir ../../scratch/gcfql/ --agent.alpha 300 --agent.actor_type best-of-n --agent.train_goal_proposer=True --agent.actor_hidden_dims 512,512,512,512 --agent.value_hidden_dims 512,512,512,512 --agent.batch_size 256 --agent.num_actions 8 --agent.num_qs 2 --agent.subgoal_steps 50 --json_path ../jsons/data.json --agent.awr_invtemp 1.0 --agent.discount 0.995 --restore_path ../../scratch/gcfql/horizon-reduction/gcfql_maze_oracle4_8/sd000_1436627854958.s_27680618_2.20250829_185820_547.gcfql_maze_oracle4_8 --restore_epoch 2000000 --q_pred_calc sample --log_interval 10 --eval_interval 50'
 [59]='python3 train_value.py --run_group train_value2_1 --env_name humanoidmaze-medium-navigate-oraclerep-v0 --agent ../agents/gcfql.py --dataset_dir ../../scratch/data/humanoidmaze-medium-navigate-v0 --train_data_size 1000000 --offline_steps 100 --save_interval 100 --save_dir ../../scratch/gcfql/ --agent.alpha 300 --agent.actor_type best-of-n --agent.train_goal_proposer=True --agent.actor_hidden_dims 512,512,512,512 --agent.value_hidden_dims 512,512,512,512 --agent.batch_size 256 --agent.num_actions 8 --agent.num_qs 2 --agent.subgoal_steps 50 --json_path ../jsons/data.json --agent.awr_invtemp 1.0 --agent.discount 0.995 --restore_path ../../scratch/gcfql/horizon-reduction/gcfql_maze_oracle4_8/sd000_1426623563374.s_27680619_3.20250829_185930_100.gcfql_maze_oracle4_8 --restore_epoch 2000000 --q_pred_calc batch --log_interval 10 --eval_interval 50'
 [60]='python3 train_value.py --run_group train_value2_1 --env_name humanoidmaze-medium-navigate-oraclerep-v0 --agent ../agents/gcfql.py --dataset_dir ../../scratch/data/humanoidmaze-medium-navigate-v0 --train_data_size 1000000 --offline_steps 100 --save_interval 100 --save_dir ../../scratch/gcfql/ --agent.alpha 300 --agent.actor_type best-of-n --agent.train_goal_proposer=True --agent.actor_hidden_dims 512,512,512,512 --agent.value_hidden_dims 512,512,512,512 --agent.batch_size 256 --agent.num_actions 8 --agent.num_qs 2 --agent.subgoal_steps 50 --json_path ../jsons/data.json --agent.awr_invtemp 1.0 --agent.discount 0.995 --restore_path ../../scratch/gcfql/horizon-reduction/gcfql_maze_oracle4_8/sd000_1426623563374.s_27680619_3.20250829_185930_100.gcfql_maze_oracle4_8 --restore_epoch 2000000 --q_pred_calc sample --log_interval 10 --eval_interval 50'
 [61]='python3 train_value.py --run_group train_value2_1 --env_name humanoidmaze-medium-navigate-oraclerep-v0 --agent ../agents/gcfql.py --dataset_dir ../../scratch/data/humanoidmaze-medium-navigate-v0 --train_data_size 1000000 --offline_steps 100 --save_interval 100 --save_dir ../../scratch/gcfql/ --agent.alpha 300 --agent.actor_type best-of-n --agent.train_goal_proposer=True --agent.actor_hidden_dims 512,512,512,512 --agent.value_hidden_dims 512,512,512,512 --agent.batch_size 256 --agent.num_actions 8 --agent.num_qs 2 --agent.subgoal_steps 50 --json_path ../jsons/data.json --agent.awr_invtemp 1.0 --agent.discount 0.995 --restore_path ../../scratch/gcfql/horizon-reduction/gcfql_maze_oracle4_8/sd000_1414600722027.s_27680590_6.20250829_185845_686.gcfql_maze_oracle4_8 --restore_epoch 2000000 --q_pred_calc batch --log_interval 10 --eval_interval 50'
 [62]='python3 train_value.py --run_group train_value2_1 --env_name humanoidmaze-medium-navigate-oraclerep-v0 --agent ../agents/gcfql.py --dataset_dir ../../scratch/data/humanoidmaze-medium-navigate-v0 --train_data_size 1000000 --offline_steps 100 --save_interval 100 --save_dir ../../scratch/gcfql/ --agent.alpha 300 --agent.actor_type best-of-n --agent.train_goal_proposer=True --agent.actor_hidden_dims 512,512,512,512 --agent.value_hidden_dims 512,512,512,512 --agent.batch_size 256 --agent.num_actions 8 --agent.num_qs 2 --agent.subgoal_steps 50 --json_path ../jsons/data.json --agent.awr_invtemp 1.0 --agent.discount 0.995 --restore_path ../../scratch/gcfql/horizon-reduction/gcfql_maze_oracle4_8/sd000_1414600722027.s_27680590_6.20250829_185845_686.gcfql_maze_oracle4_8 --restore_epoch 2000000 --q_pred_calc sample --log_interval 10 --eval_interval 50'
 [63]='python3 train_value.py --run_group train_value2_1 --env_name humanoidmaze-medium-navigate-oraclerep-v0 --agent ../agents/gcfql.py --dataset_dir ../../scratch/data/humanoidmaze-medium-navigate-v0 --train_data_size 1000000 --offline_steps 100 --save_interval 100 --save_dir ../../scratch/gcfql/ --agent.alpha 300 --agent.actor_type best-of-n --agent.train_goal_proposer=True --agent.actor_hidden_dims 512,512,512,512 --agent.value_hidden_dims 512,512,512,512 --agent.batch_size 256 --agent.num_actions 8 --agent.num_qs 2 --agent.subgoal_steps 50 --json_path ../jsons/data.json --agent.awr_invtemp 1.0 --agent.discount 0.995 --restore_path ../../scratch/gcfql/horizon-reduction/gcfql_maze_oracle4_8/sd000_1414321273454.s_27680627_5.20250829_185845_775.gcfql_maze_oracle4_8 --restore_epoch 2000000 --q_pred_calc batch --log_interval 10 --eval_interval 50'
 [64]='python3 train_value.py --run_group train_value2_1 --env_name humanoidmaze-medium-navigate-oraclerep-v0 --agent ../agents/gcfql.py --dataset_dir ../../scratch/data/humanoidmaze-medium-navigate-v0 --train_data_size 1000000 --offline_steps 100 --save_interval 100 --save_dir ../../scratch/gcfql/ --agent.alpha 300 --agent.actor_type best-of-n --agent.train_goal_proposer=True --agent.actor_hidden_dims 512,512,512,512 --agent.value_hidden_dims 512,512,512,512 --agent.batch_size 256 --agent.num_actions 8 --agent.num_qs 2 --agent.subgoal_steps 50 --json_path ../jsons/data.json --agent.awr_invtemp 1.0 --agent.discount 0.995 --restore_path ../../scratch/gcfql/horizon-reduction/gcfql_maze_oracle4_8/sd000_1414321273454.s_27680627_5.20250829_185845_775.gcfql_maze_oracle4_8 --restore_epoch 2000000 --q_pred_calc sample --log_interval 10 --eval_interval 50'
 [65]='python3 train_value.py --run_group train_value2_1 --env_name humanoidmaze-medium-navigate-oraclerep-v0 --agent ../agents/gcfql.py --dataset_dir ../../scratch/data/humanoidmaze-medium-navigate-v0 --train_data_size 1000000 --offline_steps 100 --save_interval 100 --save_dir ../../scratch/gcfql/ --agent.alpha 300 --agent.actor_type best-of-n --agent.train_goal_proposer=True --agent.actor_hidden_dims 512,512,512,512 --agent.value_hidden_dims 512,512,512,512 --agent.batch_size 256 --agent.num_actions 8 --agent.num_qs 2 --agent.subgoal_steps 50 --json_path ../jsons/data.json --agent.awr_invtemp 1.0 --agent.discount 0.995 --restore_path ../../scratch/gcfql/horizon-reduction/gcfql_maze_oracle4_8/sd000_1452282852974.s_27680618_2.20250829_185841_310.gcfql_maze_oracle4_8 --restore_epoch 2000000 --q_pred_calc batch --log_interval 10 --eval_interval 50'
 [66]='python3 train_value.py --run_group train_value2_1 --env_name humanoidmaze-medium-navigate-oraclerep-v0 --agent ../agents/gcfql.py --dataset_dir ../../scratch/data/humanoidmaze-medium-navigate-v0 --train_data_size 1000000 --offline_steps 100 --save_interval 100 --save_dir ../../scratch/gcfql/ --agent.alpha 300 --agent.actor_type best-of-n --agent.train_goal_proposer=True --agent.actor_hidden_dims 512,512,512,512 --agent.value_hidden_dims 512,512,512,512 --agent.batch_size 256 --agent.num_actions 8 --agent.num_qs 2 --agent.subgoal_steps 50 --json_path ../jsons/data.json --agent.awr_invtemp 1.0 --agent.discount 0.995 --restore_path ../../scratch/gcfql/horizon-reduction/gcfql_maze_oracle4_8/sd000_1452282852974.s_27680618_2.20250829_185841_310.gcfql_maze_oracle4_8 --restore_epoch 2000000 --q_pred_calc sample --log_interval 10 --eval_interval 50'
 [67]='python3 train_value.py --run_group train_value2_1 --env_name humanoidmaze-medium-navigate-oraclerep-v0 --agent ../agents/gcfql.py --dataset_dir ../../scratch/data/humanoidmaze-medium-navigate-v0 --train_data_size 1000000 --offline_steps 100 --save_interval 100 --save_dir ../../scratch/gcfql/ --agent.alpha 300 --agent.actor_type best-of-n --agent.train_goal_proposer=True --agent.actor_hidden_dims 512,512,512,512 --agent.value_hidden_dims 512,512,512,512 --agent.batch_size 256 --agent.num_actions 8 --agent.num_qs 2 --agent.subgoal_steps 50 --json_path ../jsons/data.json --agent.awr_invtemp 1.0 --agent.discount 0.995 --restore_path ../../scratch/gcfql/horizon-reduction/gcfql_maze_oracle4_8/sd000_1448103063147.s_27680617_1.20250829_190015_646.gcfql_maze_oracle4_8 --restore_epoch 2000000 --q_pred_calc batch --log_interval 10 --eval_interval 50'
 [68]='python3 train_value.py --run_group train_value2_1 --env_name humanoidmaze-medium-navigate-oraclerep-v0 --agent ../agents/gcfql.py --dataset_dir ../../scratch/data/humanoidmaze-medium-navigate-v0 --train_data_size 1000000 --offline_steps 100 --save_interval 100 --save_dir ../../scratch/gcfql/ --agent.alpha 300 --agent.actor_type best-of-n --agent.train_goal_proposer=True --agent.actor_hidden_dims 512,512,512,512 --agent.value_hidden_dims 512,512,512,512 --agent.batch_size 256 --agent.num_actions 8 --agent.num_qs 2 --agent.subgoal_steps 50 --json_path ../jsons/data.json --agent.awr_invtemp 1.0 --agent.discount 0.995 --restore_path ../../scratch/gcfql/horizon-reduction/gcfql_maze_oracle4_8/sd000_1448103063147.s_27680617_1.20250829_190015_646.gcfql_maze_oracle4_8 --restore_epoch 2000000 --q_pred_calc sample --log_interval 10 --eval_interval 50'
 [69]='python3 train_value.py --run_group train_value2_1 --env_name humanoidmaze-medium-navigate-oraclerep-v0 --agent ../agents/gcfql.py --dataset_dir ../../scratch/data/humanoidmaze-medium-navigate-v0 --train_data_size 1000000 --offline_steps 100 --save_interval 100 --save_dir ../../scratch/gcfql/ --agent.alpha 300 --agent.actor_type best-of-n --agent.train_goal_proposer=True --agent.actor_hidden_dims 512,512,512,512 --agent.value_hidden_dims 512,512,512,512 --agent.batch_size 256 --agent.num_actions 8 --agent.num_qs 2 --agent.subgoal_steps 50 --json_path ../jsons/data.json --agent.awr_invtemp 1.0 --agent.discount 0.995 --restore_path ../../scratch/gcfql/horizon-reduction/gcfql_maze_oracle4_8/sd000_1441449117294.s_27680626_4.20250829_185845_562.gcfql_maze_oracle4_8 --restore_epoch 2000000 --q_pred_calc batch --log_interval 10 --eval_interval 50'
 [70]='python3 train_value.py --run_group train_value2_1 --env_name humanoidmaze-medium-navigate-oraclerep-v0 --agent ../agents/gcfql.py --dataset_dir ../../scratch/data/humanoidmaze-medium-navigate-v0 --train_data_size 1000000 --offline_steps 100 --save_interval 100 --save_dir ../../scratch/gcfql/ --agent.alpha 300 --agent.actor_type best-of-n --agent.train_goal_proposer=True --agent.actor_hidden_dims 512,512,512,512 --agent.value_hidden_dims 512,512,512,512 --agent.batch_size 256 --agent.num_actions 8 --agent.num_qs 2 --agent.subgoal_steps 50 --json_path ../jsons/data.json --agent.awr_invtemp 1.0 --agent.discount 0.995 --restore_path ../../scratch/gcfql/horizon-reduction/gcfql_maze_oracle4_8/sd000_1441449117294.s_27680626_4.20250829_185845_562.gcfql_maze_oracle4_8 --restore_epoch 2000000 --q_pred_calc sample --log_interval 10 --eval_interval 50'
 [71]='python3 train_value.py --run_group train_value2_1 --env_name humanoidmaze-medium-navigate-oraclerep-v0 --agent ../agents/gcfql.py --dataset_dir ../../scratch/data/humanoidmaze-medium-navigate-v0 --train_data_size 1000000 --offline_steps 100 --save_interval 100 --save_dir ../../scratch/gcfql/ --agent.alpha 300 --agent.actor_type best-of-n --agent.train_goal_proposer=True --agent.actor_hidden_dims 512,512,512,512 --agent.value_hidden_dims 512,512,512,512 --agent.batch_size 256 --agent.num_actions 8 --agent.num_qs 2 --agent.subgoal_steps 50 --json_path ../jsons/data.json --agent.awr_invtemp 1.0 --agent.discount 0.995 --restore_path ../../scratch/gcfql/horizon-reduction/gcfql_maze_oracle4_8/sd000_1433843123822.s_27680627_5.20250829_185906_465.gcfql_maze_oracle4_8 --restore_epoch 2000000 --q_pred_calc batch --log_interval 10 --eval_interval 50'
 [72]='python3 train_value.py --run_group train_value2_1 --env_name humanoidmaze-medium-navigate-oraclerep-v0 --agent ../agents/gcfql.py --dataset_dir ../../scratch/data/humanoidmaze-medium-navigate-v0 --train_data_size 1000000 --offline_steps 100 --save_interval 100 --save_dir ../../scratch/gcfql/ --agent.alpha 300 --agent.actor_type best-of-n --agent.train_goal_proposer=True --agent.actor_hidden_dims 512,512,512,512 --agent.value_hidden_dims 512,512,512,512 --agent.batch_size 256 --agent.num_actions 8 --agent.num_qs 2 --agent.subgoal_steps 50 --json_path ../jsons/data.json --agent.awr_invtemp 1.0 --agent.discount 0.995 --restore_path ../../scratch/gcfql/horizon-reduction/gcfql_maze_oracle4_8/sd000_1433843123822.s_27680627_5.20250829_185906_465.gcfql_maze_oracle4_8 --restore_epoch 2000000 --q_pred_calc sample --log_interval 10 --eval_interval 50'
 [73]='python3 train_value.py --run_group train_value2_1 --env_name humanoidmaze-medium-navigate-oraclerep-v0 --agent ../agents/gcfql.py --dataset_dir ../../scratch/data/humanoidmaze-medium-navigate-v0 --train_data_size 1000000 --offline_steps 100 --save_interval 100 --save_dir ../../scratch/gcfql/ --agent.alpha 300 --agent.actor_type best-of-n --agent.train_goal_proposer=True --agent.actor_hidden_dims 512,512,512,512 --agent.value_hidden_dims 512,512,512,512 --agent.batch_size 256 --agent.num_actions 8 --agent.num_qs 2 --agent.subgoal_steps 100 --json_path ../jsons/data.json --agent.awr_invtemp 1.0 --agent.discount 0.995 --restore_path ../../scratch/gcfql/horizon-reduction/gcfql_maze_oracle4_8/sd000_1456162036334.s_27680590_6.20250829_185905_857.gcfql_maze_oracle4_8 --restore_epoch 2000000 --q_pred_calc batch --log_interval 10 --eval_interval 50'
 [74]='python3 train_value.py --run_group train_value2_1 --env_name humanoidmaze-medium-navigate-oraclerep-v0 --agent ../agents/gcfql.py --dataset_dir ../../scratch/data/humanoidmaze-medium-navigate-v0 --train_data_size 1000000 --offline_steps 100 --save_interval 100 --save_dir ../../scratch/gcfql/ --agent.alpha 300 --agent.actor_type best-of-n --agent.train_goal_proposer=True --agent.actor_hidden_dims 512,512,512,512 --agent.value_hidden_dims 512,512,512,512 --agent.batch_size 256 --agent.num_actions 8 --agent.num_qs 2 --agent.subgoal_steps 100 --json_path ../jsons/data.json --agent.awr_invtemp 1.0 --agent.discount 0.995 --restore_path ../../scratch/gcfql/horizon-reduction/gcfql_maze_oracle4_8/sd000_1456162036334.s_27680590_6.20250829_185905_857.gcfql_maze_oracle4_8 --restore_epoch 2000000 --q_pred_calc sample --log_interval 10 --eval_interval 50'
 [75]='python3 train_value.py --run_group train_value2_1 --env_name humanoidmaze-medium-navigate-oraclerep-v0 --agent ../agents/gcfql.py --dataset_dir ../../scratch/data/humanoidmaze-medium-navigate-v0 --train_data_size 1000000 --offline_steps 100 --save_interval 100 --save_dir ../../scratch/gcfql/ --agent.alpha 300 --agent.actor_type best-of-n --agent.train_goal_proposer=True --agent.actor_hidden_dims 512,512,512,512 --agent.value_hidden_dims 512,512,512,512 --agent.batch_size 256 --agent.num_actions 8 --agent.num_qs 2 --agent.subgoal_steps 100 --json_path ../jsons/data.json --agent.awr_invtemp 1.0 --agent.discount 0.995 --restore_path ../../scratch/gcfql/horizon-reduction/gcfql_maze_oracle4_8/sd000_1453467320942.s_27680626_4.20250829_185906_336.gcfql_maze_oracle4_8 --restore_epoch 2000000 --q_pred_calc batch --log_interval 10 --eval_interval 50'
 [76]='python3 train_value.py --run_group train_value2_1 --env_name humanoidmaze-medium-navigate-oraclerep-v0 --agent ../agents/gcfql.py --dataset_dir ../../scratch/data/humanoidmaze-medium-navigate-v0 --train_data_size 1000000 --offline_steps 100 --save_interval 100 --save_dir ../../scratch/gcfql/ --agent.alpha 300 --agent.actor_type best-of-n --agent.train_goal_proposer=True --agent.actor_hidden_dims 512,512,512,512 --agent.value_hidden_dims 512,512,512,512 --agent.batch_size 256 --agent.num_actions 8 --agent.num_qs 2 --agent.subgoal_steps 100 --json_path ../jsons/data.json --agent.awr_invtemp 1.0 --agent.discount 0.995 --restore_path ../../scratch/gcfql/horizon-reduction/gcfql_maze_oracle4_8/sd000_1453467320942.s_27680626_4.20250829_185906_336.gcfql_maze_oracle4_8 --restore_epoch 2000000 --q_pred_calc sample --log_interval 10 --eval_interval 50'
 [77]='python3 train_value.py --run_group train_value2_1 --env_name humanoidmaze-medium-navigate-oraclerep-v0 --agent ../agents/gcfql.py --dataset_dir ../../scratch/data/humanoidmaze-medium-navigate-v0 --train_data_size 1000000 --offline_steps 100 --save_interval 100 --save_dir ../../scratch/gcfql/ --agent.alpha 300 --agent.actor_type best-of-n --agent.train_goal_proposer=True --agent.actor_hidden_dims 512,512,512,512 --agent.value_hidden_dims 512,512,512,512 --agent.batch_size 256 --agent.num_actions 8 --agent.num_qs 2 --agent.subgoal_steps 100 --json_path ../jsons/data.json --agent.awr_invtemp 1.0 --agent.discount 0.995 --restore_path ../../scratch/gcfql/horizon-reduction/gcfql_maze_oracle4_8/sd000_1448342040171.s_27680619_3.20250829_185930_100.gcfql_maze_oracle4_8 --restore_epoch 2000000 --q_pred_calc batch --log_interval 10 --eval_interval 50'
 [78]='python3 train_value.py --run_group train_value2_1 --env_name humanoidmaze-medium-navigate-oraclerep-v0 --agent ../agents/gcfql.py --dataset_dir ../../scratch/data/humanoidmaze-medium-navigate-v0 --train_data_size 1000000 --offline_steps 100 --save_interval 100 --save_dir ../../scratch/gcfql/ --agent.alpha 300 --agent.actor_type best-of-n --agent.train_goal_proposer=True --agent.actor_hidden_dims 512,512,512,512 --agent.value_hidden_dims 512,512,512,512 --agent.batch_size 256 --agent.num_actions 8 --agent.num_qs 2 --agent.subgoal_steps 100 --json_path ../jsons/data.json --agent.awr_invtemp 1.0 --agent.discount 0.995 --restore_path ../../scratch/gcfql/horizon-reduction/gcfql_maze_oracle4_8/sd000_1448342040171.s_27680619_3.20250829_185930_100.gcfql_maze_oracle4_8 --restore_epoch 2000000 --q_pred_calc sample --log_interval 10 --eval_interval 50'
 [79]='python3 train_value.py --run_group train_value2_1 --env_name humanoidmaze-medium-navigate-oraclerep-v0 --agent ../agents/gcfql.py --dataset_dir ../../scratch/data/humanoidmaze-medium-navigate-v0 --train_data_size 1000000 --offline_steps 100 --save_interval 100 --save_dir ../../scratch/gcfql/ --agent.alpha 300 --agent.actor_type best-of-n --agent.train_goal_proposer=True --agent.actor_hidden_dims 512,512,512,512 --agent.value_hidden_dims 512,512,512,512 --agent.batch_size 256 --agent.num_actions 8 --agent.num_qs 2 --agent.subgoal_steps 100 --json_path ../jsons/data.json --agent.awr_invtemp 1.0 --agent.discount 0.995 --restore_path ../../scratch/gcfql/horizon-reduction/gcfql_maze_oracle4_8/sd000_1438812371566.s_27680617_1.20250829_190015_646.gcfql_maze_oracle4_8 --restore_epoch 2000000 --q_pred_calc batch --log_interval 10 --eval_interval 50'
 [80]='python3 train_value.py --run_group train_value2_1 --env_name humanoidmaze-medium-navigate-oraclerep-v0 --agent ../agents/gcfql.py --dataset_dir ../../scratch/data/humanoidmaze-medium-navigate-v0 --train_data_size 1000000 --offline_steps 100 --save_interval 100 --save_dir ../../scratch/gcfql/ --agent.alpha 300 --agent.actor_type best-of-n --agent.train_goal_proposer=True --agent.actor_hidden_dims 512,512,512,512 --agent.value_hidden_dims 512,512,512,512 --agent.batch_size 256 --agent.num_actions 8 --agent.num_qs 2 --agent.subgoal_steps 100 --json_path ../jsons/data.json --agent.awr_invtemp 1.0 --agent.discount 0.995 --restore_path ../../scratch/gcfql/horizon-reduction/gcfql_maze_oracle4_8/sd000_1438812371566.s_27680617_1.20250829_190015_646.gcfql_maze_oracle4_8 --restore_epoch 2000000 --q_pred_calc sample --log_interval 10 --eval_interval 50'
 [81]='python3 train_value.py --run_group train_value2_1 --env_name humanoidmaze-medium-navigate-oraclerep-v0 --agent ../agents/gcfql.py --dataset_dir ../../scratch/data/humanoidmaze-medium-navigate-v0 --train_data_size 1000000 --offline_steps 100 --save_interval 100 --save_dir ../../scratch/gcfql/ --agent.alpha 300 --agent.actor_type best-of-n --agent.train_goal_proposer=True --agent.actor_hidden_dims 512,512,512,512 --agent.value_hidden_dims 512,512,512,512 --agent.batch_size 256 --agent.num_actions 8 --agent.num_qs 2 --agent.subgoal_steps 100 --json_path ../jsons/data.json --agent.awr_invtemp 1.0 --agent.discount 0.995 --restore_path ../../scratch/gcfql/horizon-reduction/gcfql_maze_oracle4_8/sd000_1436627854958.s_27680618_2.20250829_185820_547.gcfql_maze_oracle4_8 --restore_epoch 2000000 --q_pred_calc batch --log_interval 10 --eval_interval 50'
 [82]='python3 train_value.py --run_group train_value2_1 --env_name humanoidmaze-medium-navigate-oraclerep-v0 --agent ../agents/gcfql.py --dataset_dir ../../scratch/data/humanoidmaze-medium-navigate-v0 --train_data_size 1000000 --offline_steps 100 --save_interval 100 --save_dir ../../scratch/gcfql/ --agent.alpha 300 --agent.actor_type best-of-n --agent.train_goal_proposer=True --agent.actor_hidden_dims 512,512,512,512 --agent.value_hidden_dims 512,512,512,512 --agent.batch_size 256 --agent.num_actions 8 --agent.num_qs 2 --agent.subgoal_steps 100 --json_path ../jsons/data.json --agent.awr_invtemp 1.0 --agent.discount 0.995 --restore_path ../../scratch/gcfql/horizon-reduction/gcfql_maze_oracle4_8/sd000_1436627854958.s_27680618_2.20250829_185820_547.gcfql_maze_oracle4_8 --restore_epoch 2000000 --q_pred_calc sample --log_interval 10 --eval_interval 50'
 [83]='python3 train_value.py --run_group train_value2_1 --env_name humanoidmaze-medium-navigate-oraclerep-v0 --agent ../agents/gcfql.py --dataset_dir ../../scratch/data/humanoidmaze-medium-navigate-v0 --train_data_size 1000000 --offline_steps 100 --save_interval 100 --save_dir ../../scratch/gcfql/ --agent.alpha 300 --agent.actor_type best-of-n --agent.train_goal_proposer=True --agent.actor_hidden_dims 512,512,512,512 --agent.value_hidden_dims 512,512,512,512 --agent.batch_size 256 --agent.num_actions 8 --agent.num_qs 2 --agent.subgoal_steps 100 --json_path ../jsons/data.json --agent.awr_invtemp 1.0 --agent.discount 0.995 --restore_path ../../scratch/gcfql/horizon-reduction/gcfql_maze_oracle4_8/sd000_1426623563374.s_27680619_3.20250829_185930_100.gcfql_maze_oracle4_8 --restore_epoch 2000000 --q_pred_calc batch --log_interval 10 --eval_interval 50'
 [84]='python3 train_value.py --run_group train_value2_1 --env_name humanoidmaze-medium-navigate-oraclerep-v0 --agent ../agents/gcfql.py --dataset_dir ../../scratch/data/humanoidmaze-medium-navigate-v0 --train_data_size 1000000 --offline_steps 100 --save_interval 100 --save_dir ../../scratch/gcfql/ --agent.alpha 300 --agent.actor_type best-of-n --agent.train_goal_proposer=True --agent.actor_hidden_dims 512,512,512,512 --agent.value_hidden_dims 512,512,512,512 --agent.batch_size 256 --agent.num_actions 8 --agent.num_qs 2 --agent.subgoal_steps 100 --json_path ../jsons/data.json --agent.awr_invtemp 1.0 --agent.discount 0.995 --restore_path ../../scratch/gcfql/horizon-reduction/gcfql_maze_oracle4_8/sd000_1426623563374.s_27680619_3.20250829_185930_100.gcfql_maze_oracle4_8 --restore_epoch 2000000 --q_pred_calc sample --log_interval 10 --eval_interval 50'
 [85]='python3 train_value.py --run_group train_value2_1 --env_name humanoidmaze-medium-navigate-oraclerep-v0 --agent ../agents/gcfql.py --dataset_dir ../../scratch/data/humanoidmaze-medium-navigate-v0 --train_data_size 1000000 --offline_steps 100 --save_interval 100 --save_dir ../../scratch/gcfql/ --agent.alpha 300 --agent.actor_type best-of-n --agent.train_goal_proposer=True --agent.actor_hidden_dims 512,512,512,512 --agent.value_hidden_dims 512,512,512,512 --agent.batch_size 256 --agent.num_actions 8 --agent.num_qs 2 --agent.subgoal_steps 100 --json_path ../jsons/data.json --agent.awr_invtemp 1.0 --agent.discount 0.995 --restore_path ../../scratch/gcfql/horizon-reduction/gcfql_maze_oracle4_8/sd000_1414600722027.s_27680590_6.20250829_185845_686.gcfql_maze_oracle4_8 --restore_epoch 2000000 --q_pred_calc batch --log_interval 10 --eval_interval 50'
 [86]='python3 train_value.py --run_group train_value2_1 --env_name humanoidmaze-medium-navigate-oraclerep-v0 --agent ../agents/gcfql.py --dataset_dir ../../scratch/data/humanoidmaze-medium-navigate-v0 --train_data_size 1000000 --offline_steps 100 --save_interval 100 --save_dir ../../scratch/gcfql/ --agent.alpha 300 --agent.actor_type best-of-n --agent.train_goal_proposer=True --agent.actor_hidden_dims 512,512,512,512 --agent.value_hidden_dims 512,512,512,512 --agent.batch_size 256 --agent.num_actions 8 --agent.num_qs 2 --agent.subgoal_steps 100 --json_path ../jsons/data.json --agent.awr_invtemp 1.0 --agent.discount 0.995 --restore_path ../../scratch/gcfql/horizon-reduction/gcfql_maze_oracle4_8/sd000_1414600722027.s_27680590_6.20250829_185845_686.gcfql_maze_oracle4_8 --restore_epoch 2000000 --q_pred_calc sample --log_interval 10 --eval_interval 50'
 [87]='python3 train_value.py --run_group train_value2_1 --env_name humanoidmaze-medium-navigate-oraclerep-v0 --agent ../agents/gcfql.py --dataset_dir ../../scratch/data/humanoidmaze-medium-navigate-v0 --train_data_size 1000000 --offline_steps 100 --save_interval 100 --save_dir ../../scratch/gcfql/ --agent.alpha 300 --agent.actor_type best-of-n --agent.train_goal_proposer=True --agent.actor_hidden_dims 512,512,512,512 --agent.value_hidden_dims 512,512,512,512 --agent.batch_size 256 --agent.num_actions 8 --agent.num_qs 2 --agent.subgoal_steps 100 --json_path ../jsons/data.json --agent.awr_invtemp 1.0 --agent.discount 0.995 --restore_path ../../scratch/gcfql/horizon-reduction/gcfql_maze_oracle4_8/sd000_1414321273454.s_27680627_5.20250829_185845_775.gcfql_maze_oracle4_8 --restore_epoch 2000000 --q_pred_calc batch --log_interval 10 --eval_interval 50'
 [88]='python3 train_value.py --run_group train_value2_1 --env_name humanoidmaze-medium-navigate-oraclerep-v0 --agent ../agents/gcfql.py --dataset_dir ../../scratch/data/humanoidmaze-medium-navigate-v0 --train_data_size 1000000 --offline_steps 100 --save_interval 100 --save_dir ../../scratch/gcfql/ --agent.alpha 300 --agent.actor_type best-of-n --agent.train_goal_proposer=True --agent.actor_hidden_dims 512,512,512,512 --agent.value_hidden_dims 512,512,512,512 --agent.batch_size 256 --agent.num_actions 8 --agent.num_qs 2 --agent.subgoal_steps 100 --json_path ../jsons/data.json --agent.awr_invtemp 1.0 --agent.discount 0.995 --restore_path ../../scratch/gcfql/horizon-reduction/gcfql_maze_oracle4_8/sd000_1414321273454.s_27680627_5.20250829_185845_775.gcfql_maze_oracle4_8 --restore_epoch 2000000 --q_pred_calc sample --log_interval 10 --eval_interval 50'
 [89]='python3 train_value.py --run_group train_value2_1 --env_name humanoidmaze-medium-navigate-oraclerep-v0 --agent ../agents/gcfql.py --dataset_dir ../../scratch/data/humanoidmaze-medium-navigate-v0 --train_data_size 1000000 --offline_steps 100 --save_interval 100 --save_dir ../../scratch/gcfql/ --agent.alpha 300 --agent.actor_type best-of-n --agent.train_goal_proposer=True --agent.actor_hidden_dims 512,512,512,512 --agent.value_hidden_dims 512,512,512,512 --agent.batch_size 256 --agent.num_actions 8 --agent.num_qs 2 --agent.subgoal_steps 100 --json_path ../jsons/data.json --agent.awr_invtemp 1.0 --agent.discount 0.995 --restore_path ../../scratch/gcfql/horizon-reduction/gcfql_maze_oracle4_8/sd000_1452282852974.s_27680618_2.20250829_185841_310.gcfql_maze_oracle4_8 --restore_epoch 2000000 --q_pred_calc batch --log_interval 10 --eval_interval 50'
 [90]='python3 train_value.py --run_group train_value2_1 --env_name humanoidmaze-medium-navigate-oraclerep-v0 --agent ../agents/gcfql.py --dataset_dir ../../scratch/data/humanoidmaze-medium-navigate-v0 --train_data_size 1000000 --offline_steps 100 --save_interval 100 --save_dir ../../scratch/gcfql/ --agent.alpha 300 --agent.actor_type best-of-n --agent.train_goal_proposer=True --agent.actor_hidden_dims 512,512,512,512 --agent.value_hidden_dims 512,512,512,512 --agent.batch_size 256 --agent.num_actions 8 --agent.num_qs 2 --agent.subgoal_steps 100 --json_path ../jsons/data.json --agent.awr_invtemp 1.0 --agent.discount 0.995 --restore_path ../../scratch/gcfql/horizon-reduction/gcfql_maze_oracle4_8/sd000_1452282852974.s_27680618_2.20250829_185841_310.gcfql_maze_oracle4_8 --restore_epoch 2000000 --q_pred_calc sample --log_interval 10 --eval_interval 50'
 [91]='python3 train_value.py --run_group train_value2_1 --env_name humanoidmaze-medium-navigate-oraclerep-v0 --agent ../agents/gcfql.py --dataset_dir ../../scratch/data/humanoidmaze-medium-navigate-v0 --train_data_size 1000000 --offline_steps 100 --save_interval 100 --save_dir ../../scratch/gcfql/ --agent.alpha 300 --agent.actor_type best-of-n --agent.train_goal_proposer=True --agent.actor_hidden_dims 512,512,512,512 --agent.value_hidden_dims 512,512,512,512 --agent.batch_size 256 --agent.num_actions 8 --agent.num_qs 2 --agent.subgoal_steps 100 --json_path ../jsons/data.json --agent.awr_invtemp 1.0 --agent.discount 0.995 --restore_path ../../scratch/gcfql/horizon-reduction/gcfql_maze_oracle4_8/sd000_1448103063147.s_27680617_1.20250829_190015_646.gcfql_maze_oracle4_8 --restore_epoch 2000000 --q_pred_calc batch --log_interval 10 --eval_interval 50'
 [92]='python3 train_value.py --run_group train_value2_1 --env_name humanoidmaze-medium-navigate-oraclerep-v0 --agent ../agents/gcfql.py --dataset_dir ../../scratch/data/humanoidmaze-medium-navigate-v0 --train_data_size 1000000 --offline_steps 100 --save_interval 100 --save_dir ../../scratch/gcfql/ --agent.alpha 300 --agent.actor_type best-of-n --agent.train_goal_proposer=True --agent.actor_hidden_dims 512,512,512,512 --agent.value_hidden_dims 512,512,512,512 --agent.batch_size 256 --agent.num_actions 8 --agent.num_qs 2 --agent.subgoal_steps 100 --json_path ../jsons/data.json --agent.awr_invtemp 1.0 --agent.discount 0.995 --restore_path ../../scratch/gcfql/horizon-reduction/gcfql_maze_oracle4_8/sd000_1448103063147.s_27680617_1.20250829_190015_646.gcfql_maze_oracle4_8 --restore_epoch 2000000 --q_pred_calc sample --log_interval 10 --eval_interval 50'
 [93]='python3 train_value.py --run_group train_value2_1 --env_name humanoidmaze-medium-navigate-oraclerep-v0 --agent ../agents/gcfql.py --dataset_dir ../../scratch/data/humanoidmaze-medium-navigate-v0 --train_data_size 1000000 --offline_steps 100 --save_interval 100 --save_dir ../../scratch/gcfql/ --agent.alpha 300 --agent.actor_type best-of-n --agent.train_goal_proposer=True --agent.actor_hidden_dims 512,512,512,512 --agent.value_hidden_dims 512,512,512,512 --agent.batch_size 256 --agent.num_actions 8 --agent.num_qs 2 --agent.subgoal_steps 100 --json_path ../jsons/data.json --agent.awr_invtemp 1.0 --agent.discount 0.995 --restore_path ../../scratch/gcfql/horizon-reduction/gcfql_maze_oracle4_8/sd000_1441449117294.s_27680626_4.20250829_185845_562.gcfql_maze_oracle4_8 --restore_epoch 2000000 --q_pred_calc batch --log_interval 10 --eval_interval 50'
 [94]='python3 train_value.py --run_group train_value2_1 --env_name humanoidmaze-medium-navigate-oraclerep-v0 --agent ../agents/gcfql.py --dataset_dir ../../scratch/data/humanoidmaze-medium-navigate-v0 --train_data_size 1000000 --offline_steps 100 --save_interval 100 --save_dir ../../scratch/gcfql/ --agent.alpha 300 --agent.actor_type best-of-n --agent.train_goal_proposer=True --agent.actor_hidden_dims 512,512,512,512 --agent.value_hidden_dims 512,512,512,512 --agent.batch_size 256 --agent.num_actions 8 --agent.num_qs 2 --agent.subgoal_steps 100 --json_path ../jsons/data.json --agent.awr_invtemp 1.0 --agent.discount 0.995 --restore_path ../../scratch/gcfql/horizon-reduction/gcfql_maze_oracle4_8/sd000_1441449117294.s_27680626_4.20250829_185845_562.gcfql_maze_oracle4_8 --restore_epoch 2000000 --q_pred_calc sample --log_interval 10 --eval_interval 50'
 [95]='python3 train_value.py --run_group train_value2_1 --env_name humanoidmaze-medium-navigate-oraclerep-v0 --agent ../agents/gcfql.py --dataset_dir ../../scratch/data/humanoidmaze-medium-navigate-v0 --train_data_size 1000000 --offline_steps 100 --save_interval 100 --save_dir ../../scratch/gcfql/ --agent.alpha 300 --agent.actor_type best-of-n --agent.train_goal_proposer=True --agent.actor_hidden_dims 512,512,512,512 --agent.value_hidden_dims 512,512,512,512 --agent.batch_size 256 --agent.num_actions 8 --agent.num_qs 2 --agent.subgoal_steps 100 --json_path ../jsons/data.json --agent.awr_invtemp 1.0 --agent.discount 0.995 --restore_path ../../scratch/gcfql/horizon-reduction/gcfql_maze_oracle4_8/sd000_1433843123822.s_27680627_5.20250829_185906_465.gcfql_maze_oracle4_8 --restore_epoch 2000000 --q_pred_calc batch --log_interval 10 --eval_interval 50'
 [96]='python3 train_value.py --run_group train_value2_1 --env_name humanoidmaze-medium-navigate-oraclerep-v0 --agent ../agents/gcfql.py --dataset_dir ../../scratch/data/humanoidmaze-medium-navigate-v0 --train_data_size 1000000 --offline_steps 100 --save_interval 100 --save_dir ../../scratch/gcfql/ --agent.alpha 300 --agent.actor_type best-of-n --agent.train_goal_proposer=True --agent.actor_hidden_dims 512,512,512,512 --agent.value_hidden_dims 512,512,512,512 --agent.batch_size 256 --agent.num_actions 8 --agent.num_qs 2 --agent.subgoal_steps 100 --json_path ../jsons/data.json --agent.awr_invtemp 1.0 --agent.discount 0.995 --restore_path ../../scratch/gcfql/horizon-reduction/gcfql_maze_oracle4_8/sd000_1433843123822.s_27680627_5.20250829_185906_465.gcfql_maze_oracle4_8 --restore_epoch 2000000 --q_pred_calc sample --log_interval 10 --eval_interval 50'
)

cd /home/jennifer/aorl/horizon_reduction

parallel --delay 20 --linebuffer -j 2 {1} ::: "${commands[@]:$COM_ID_S:$PARALLEL_N}"
