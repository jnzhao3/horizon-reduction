#!/bin/bash
#SBATCH --job-name=aorl
#SBATCH --open-mode=append
#SBATCH -o /global/scratch/users/jenniferzhao/logs/%A_%a.out
#SBATCH -e /global/scratch/users/jenniferzhao/logs/%A_%a.err
#SBATCH --time=36:00:00
#SBATCH --mem=64G
#SBATCH --cpus-per-task=4
#SBATCH --gres=gpu:A5000:1
#SBATCH --account=co_rail
#SBATCH --partition=savio4_gpu
#SBATCH --qos=rail_gpu4_high
#SBATCH --requeue
#SBATCH --array=1-11%16

TASK_ID=$((SLURM_ARRAY_TASK_ID-1))
PARALLEL_N=2
JOB_N=22

COM_ID_S=$((TASK_ID * PARALLEL_N + 1))
source ~/.bashrc
micromamba activate aorl
export PYTHONPATH="../:${PYTHONPATH}"

declare -a commands=(
 [1]='python3 train_value.py --run_group train_value1_3 --env_name humanoidmaze-large-navigate-oraclerep-v0 --agent ../agents/gcfql.py --dataset_dir ../../scratch/data/humanoidmaze-large-navigate-v0 --offline_steps 2000000 --save_interval 200000 --save_dir ../../scratch/gcfql/ --agent.alpha 300 --agent.actor_type best-of-n --agent.train_goal_proposer=True --agent.actor_hidden_dims 512,512,512,512 --agent.value_hidden_dims 512,512,512,512 --agent.batch_size 256 --agent.num_actions 8 --agent.num_qs 2 --json_path ../jsons/data.json --agent.awr_invtemp 1.0 --agent.discount 0.995 --restore_path ../../scratch/gcfql/horizon-reduction/gcfql_maze_oracle3_8/sd000_1402547812974.s_27684700_4.20250830_020259_647.gcfql_maze_oracle3_8 --restore_epoch 2000000 --q_pred_calc batch'
 [2]='python3 train_value.py --run_group train_value1_3 --env_name humanoidmaze-large-navigate-oraclerep-v0 --agent ../agents/gcfql.py --dataset_dir ../../scratch/data/humanoidmaze-large-navigate-v0 --offline_steps 2000000 --save_interval 200000 --save_dir ../../scratch/gcfql/ --agent.alpha 300 --agent.actor_type best-of-n --agent.train_goal_proposer=True --agent.actor_hidden_dims 512,512,512,512 --agent.value_hidden_dims 512,512,512,512 --agent.batch_size 256 --agent.num_actions 8 --agent.num_qs 2 --json_path ../jsons/data.json --agent.awr_invtemp 1.0 --agent.discount 0.995 --restore_path ../../scratch/gcfql/horizon-reduction/gcfql_maze_oracle3_8/sd000_1402547812974.s_27684700_4.20250830_020259_647.gcfql_maze_oracle3_8 --restore_epoch 2000000 --q_pred_calc sample'
 [3]='python3 train_value.py --run_group train_value1_3 --env_name humanoidmaze-large-navigate-oraclerep-v0 --agent ../agents/gcfql.py --dataset_dir ../../scratch/data/humanoidmaze-large-navigate-v0 --offline_steps 2000000 --save_interval 200000 --save_dir ../../scratch/gcfql/ --agent.alpha 300 --agent.actor_type best-of-n --agent.train_goal_proposer=True --agent.actor_hidden_dims 512,512,512,512 --agent.value_hidden_dims 512,512,512,512 --agent.batch_size 256 --agent.num_actions 8 --agent.num_qs 2 --json_path ../jsons/data.json --agent.awr_invtemp 1.0 --agent.discount 0.995 --restore_path ../../scratch/gcfql/horizon-reduction/gcfql_maze_oracle3_8/sd000_1414568005230.s_27684111_1.20250829_220124_123.gcfql_maze_oracle3_8 --restore_epoch 2000000 --q_pred_calc batch'
 [4]='python3 train_value.py --run_group train_value1_3 --env_name humanoidmaze-large-navigate-oraclerep-v0 --agent ../agents/gcfql.py --dataset_dir ../../scratch/data/humanoidmaze-large-navigate-v0 --offline_steps 2000000 --save_interval 200000 --save_dir ../../scratch/gcfql/ --agent.alpha 300 --agent.actor_type best-of-n --agent.train_goal_proposer=True --agent.actor_hidden_dims 512,512,512,512 --agent.value_hidden_dims 512,512,512,512 --agent.batch_size 256 --agent.num_actions 8 --agent.num_qs 2 --json_path ../jsons/data.json --agent.awr_invtemp 1.0 --agent.discount 0.995 --restore_path ../../scratch/gcfql/horizon-reduction/gcfql_maze_oracle3_8/sd000_1414568005230.s_27684111_1.20250829_220124_123.gcfql_maze_oracle3_8 --restore_epoch 2000000 --q_pred_calc sample'
 [5]='python3 train_value.py --run_group train_value1_3 --env_name humanoidmaze-large-navigate-oraclerep-v0 --agent ../agents/gcfql.py --dataset_dir ../../scratch/data/humanoidmaze-large-navigate-v0 --offline_steps 2000000 --save_interval 200000 --save_dir ../../scratch/gcfql/ --agent.alpha 300 --agent.actor_type best-of-n --agent.train_goal_proposer=True --agent.actor_hidden_dims 512,512,512,512 --agent.value_hidden_dims 512,512,512,512 --agent.batch_size 256 --agent.num_actions 8 --agent.num_qs 2 --json_path ../jsons/data.json --agent.awr_invtemp 1.0 --agent.discount 0.995 --restore_path ../../scratch/gcfql/horizon-reduction/gcfql_maze_oracle3_8/sd000_1432255779435.s_27684707_5.20250830_020510_865.gcfql_maze_oracle3_8 --restore_epoch 2000000 --q_pred_calc batch'
 [6]='python3 train_value.py --run_group train_value1_3 --env_name humanoidmaze-large-navigate-oraclerep-v0 --agent ../agents/gcfql.py --dataset_dir ../../scratch/data/humanoidmaze-large-navigate-v0 --offline_steps 2000000 --save_interval 200000 --save_dir ../../scratch/gcfql/ --agent.alpha 300 --agent.actor_type best-of-n --agent.train_goal_proposer=True --agent.actor_hidden_dims 512,512,512,512 --agent.value_hidden_dims 512,512,512,512 --agent.batch_size 256 --agent.num_actions 8 --agent.num_qs 2 --json_path ../jsons/data.json --agent.awr_invtemp 1.0 --agent.discount 0.995 --restore_path ../../scratch/gcfql/horizon-reduction/gcfql_maze_oracle3_8/sd000_1432255779435.s_27684707_5.20250830_020510_865.gcfql_maze_oracle3_8 --restore_epoch 2000000 --q_pred_calc sample'
 [7]='python3 train_value.py --run_group train_value1_3 --env_name humanoidmaze-large-navigate-oraclerep-v0 --agent ../agents/gcfql.py --dataset_dir ../../scratch/data/humanoidmaze-large-navigate-v0 --offline_steps 2000000 --save_interval 200000 --save_dir ../../scratch/gcfql/ --agent.alpha 300 --agent.actor_type best-of-n --agent.train_goal_proposer=True --agent.actor_hidden_dims 512,512,512,512 --agent.value_hidden_dims 512,512,512,512 --agent.batch_size 256 --agent.num_actions 8 --agent.num_qs 2 --json_path ../jsons/data.json --agent.awr_invtemp 1.0 --agent.discount 0.995 --restore_path ../../scratch/gcfql/horizon-reduction/gcfql_maze_oracle3_8/sd000_1433302649454.s_27684112_2.20250829_220125_578.gcfql_maze_oracle3_8 --restore_epoch 2000000 --q_pred_calc batch'
 [8]='python3 train_value.py --run_group train_value1_3 --env_name humanoidmaze-large-navigate-oraclerep-v0 --agent ../agents/gcfql.py --dataset_dir ../../scratch/data/humanoidmaze-large-navigate-v0 --offline_steps 2000000 --save_interval 200000 --save_dir ../../scratch/gcfql/ --agent.alpha 300 --agent.actor_type best-of-n --agent.train_goal_proposer=True --agent.actor_hidden_dims 512,512,512,512 --agent.value_hidden_dims 512,512,512,512 --agent.batch_size 256 --agent.num_actions 8 --agent.num_qs 2 --json_path ../jsons/data.json --agent.awr_invtemp 1.0 --agent.discount 0.995 --restore_path ../../scratch/gcfql/horizon-reduction/gcfql_maze_oracle3_8/sd000_1433302649454.s_27684112_2.20250829_220125_578.gcfql_maze_oracle3_8 --restore_epoch 2000000 --q_pred_calc sample'
 [9]='python3 train_value.py --run_group train_value1_3 --env_name humanoidmaze-large-navigate-oraclerep-v0 --agent ../agents/gcfql.py --dataset_dir ../../scratch/data/humanoidmaze-large-navigate-v0 --offline_steps 2000000 --save_interval 200000 --save_dir ../../scratch/gcfql/ --agent.alpha 300 --agent.actor_type best-of-n --agent.train_goal_proposer=True --agent.actor_hidden_dims 512,512,512,512 --agent.value_hidden_dims 512,512,512,512 --agent.batch_size 256 --agent.num_actions 8 --agent.num_qs 2 --json_path ../jsons/data.json --agent.awr_invtemp 1.0 --agent.discount 0.995 --restore_path ../../scratch/gcfql/horizon-reduction/gcfql_maze_oracle3_8/sd000_1434207663726.s_27684103_6.20250830_020534_012.gcfql_maze_oracle3_8 --restore_epoch 2000000 --q_pred_calc batch'
 [10]='python3 train_value.py --run_group train_value1_3 --env_name humanoidmaze-large-navigate-oraclerep-v0 --agent ../agents/gcfql.py --dataset_dir ../../scratch/data/humanoidmaze-large-navigate-v0 --offline_steps 2000000 --save_interval 200000 --save_dir ../../scratch/gcfql/ --agent.alpha 300 --agent.actor_type best-of-n --agent.train_goal_proposer=True --agent.actor_hidden_dims 512,512,512,512 --agent.value_hidden_dims 512,512,512,512 --agent.batch_size 256 --agent.num_actions 8 --agent.num_qs 2 --json_path ../jsons/data.json --agent.awr_invtemp 1.0 --agent.discount 0.995 --restore_path ../../scratch/gcfql/horizon-reduction/gcfql_maze_oracle3_8/sd000_1434207663726.s_27684103_6.20250830_020534_012.gcfql_maze_oracle3_8 --restore_epoch 2000000 --q_pred_calc sample'
 [11]='python3 train_value.py --run_group train_value1_3 --env_name humanoidmaze-large-navigate-oraclerep-v0 --agent ../agents/gcfql.py --dataset_dir ../../scratch/data/humanoidmaze-large-navigate-v0 --offline_steps 2000000 --save_interval 200000 --save_dir ../../scratch/gcfql/ --agent.alpha 300 --agent.actor_type best-of-n --agent.train_goal_proposer=True --agent.actor_hidden_dims 512,512,512,512 --agent.value_hidden_dims 512,512,512,512 --agent.batch_size 256 --agent.num_actions 8 --agent.num_qs 2 --json_path ../jsons/data.json --agent.awr_invtemp 1.0 --agent.discount 0.995 --restore_path ../../scratch/gcfql/horizon-reduction/gcfql_maze_oracle3_8/sd000_1436102206062.s_27684113_3.20250829_220125_148.gcfql_maze_oracle3_8 --restore_epoch 2000000 --q_pred_calc batch'
 [12]='python3 train_value.py --run_group train_value1_3 --env_name humanoidmaze-large-navigate-oraclerep-v0 --agent ../agents/gcfql.py --dataset_dir ../../scratch/data/humanoidmaze-large-navigate-v0 --offline_steps 2000000 --save_interval 200000 --save_dir ../../scratch/gcfql/ --agent.alpha 300 --agent.actor_type best-of-n --agent.train_goal_proposer=True --agent.actor_hidden_dims 512,512,512,512 --agent.value_hidden_dims 512,512,512,512 --agent.batch_size 256 --agent.num_actions 8 --agent.num_qs 2 --json_path ../jsons/data.json --agent.awr_invtemp 1.0 --agent.discount 0.995 --restore_path ../../scratch/gcfql/horizon-reduction/gcfql_maze_oracle3_8/sd000_1436102206062.s_27684113_3.20250829_220125_148.gcfql_maze_oracle3_8 --restore_epoch 2000000 --q_pred_calc sample'
 [13]='python3 train_value.py --run_group train_value1_3 --env_name humanoidmaze-large-navigate-oraclerep-v0 --agent ../agents/gcfql.py --dataset_dir ../../scratch/data/humanoidmaze-large-navigate-v0 --offline_steps 2000000 --save_interval 200000 --save_dir ../../scratch/gcfql/ --agent.alpha 300 --agent.actor_type best-of-n --agent.train_goal_proposer=True --agent.actor_hidden_dims 512,512,512,512 --agent.value_hidden_dims 512,512,512,512 --agent.batch_size 256 --agent.num_actions 8 --agent.num_qs 2 --json_path ../jsons/data.json --agent.awr_invtemp 1.0 --agent.discount 0.995 --restore_path ../../scratch/gcfql/horizon-reduction/gcfql_maze_oracle3_8/sd000_1438068558443.s_27684103_6.20250830_020534_012.gcfql_maze_oracle3_8 --restore_epoch 2000000 --q_pred_calc batch'
 [14]='python3 train_value.py --run_group train_value1_3 --env_name humanoidmaze-large-navigate-oraclerep-v0 --agent ../agents/gcfql.py --dataset_dir ../../scratch/data/humanoidmaze-large-navigate-v0 --offline_steps 2000000 --save_interval 200000 --save_dir ../../scratch/gcfql/ --agent.alpha 300 --agent.actor_type best-of-n --agent.train_goal_proposer=True --agent.actor_hidden_dims 512,512,512,512 --agent.value_hidden_dims 512,512,512,512 --agent.batch_size 256 --agent.num_actions 8 --agent.num_qs 2 --json_path ../jsons/data.json --agent.awr_invtemp 1.0 --agent.discount 0.995 --restore_path ../../scratch/gcfql/horizon-reduction/gcfql_maze_oracle3_8/sd000_1438068558443.s_27684103_6.20250830_020534_012.gcfql_maze_oracle3_8 --restore_epoch 2000000 --q_pred_calc sample'
 [15]='python3 train_value.py --run_group train_value1_3 --env_name humanoidmaze-large-navigate-oraclerep-v0 --agent ../agents/gcfql.py --dataset_dir ../../scratch/data/humanoidmaze-large-navigate-v0 --offline_steps 2000000 --save_interval 200000 --save_dir ../../scratch/gcfql/ --agent.alpha 300 --agent.actor_type best-of-n --agent.train_goal_proposer=True --agent.actor_hidden_dims 512,512,512,512 --agent.value_hidden_dims 512,512,512,512 --agent.batch_size 256 --agent.num_actions 8 --agent.num_qs 2 --json_path ../jsons/data.json --agent.awr_invtemp 1.0 --agent.discount 0.995 --restore_path ../../scratch/gcfql/horizon-reduction/gcfql_maze_oracle3_8/sd000_1444406050411.s_27684111_1.20250829_220124_123.gcfql_maze_oracle3_8 --restore_epoch 2000000 --q_pred_calc batch'
 [16]='python3 train_value.py --run_group train_value1_3 --env_name humanoidmaze-large-navigate-oraclerep-v0 --agent ../agents/gcfql.py --dataset_dir ../../scratch/data/humanoidmaze-large-navigate-v0 --offline_steps 2000000 --save_interval 200000 --save_dir ../../scratch/gcfql/ --agent.alpha 300 --agent.actor_type best-of-n --agent.train_goal_proposer=True --agent.actor_hidden_dims 512,512,512,512 --agent.value_hidden_dims 512,512,512,512 --agent.batch_size 256 --agent.num_actions 8 --agent.num_qs 2 --json_path ../jsons/data.json --agent.awr_invtemp 1.0 --agent.discount 0.995 --restore_path ../../scratch/gcfql/horizon-reduction/gcfql_maze_oracle3_8/sd000_1444406050411.s_27684111_1.20250829_220124_123.gcfql_maze_oracle3_8 --restore_epoch 2000000 --q_pred_calc sample'
 [17]='python3 train_value.py --run_group train_value1_3 --env_name humanoidmaze-large-navigate-oraclerep-v0 --agent ../agents/gcfql.py --dataset_dir ../../scratch/data/humanoidmaze-large-navigate-v0 --offline_steps 2000000 --save_interval 200000 --save_dir ../../scratch/gcfql/ --agent.alpha 300 --agent.actor_type best-of-n --agent.train_goal_proposer=True --agent.actor_hidden_dims 512,512,512,512 --agent.value_hidden_dims 512,512,512,512 --agent.batch_size 256 --agent.num_actions 8 --agent.num_qs 2 --json_path ../jsons/data.json --agent.awr_invtemp 1.0 --agent.discount 0.995 --restore_path ../../scratch/gcfql/horizon-reduction/gcfql_maze_oracle3_8/sd000_1447825734251.s_27684113_3.20250829_220125_147.gcfql_maze_oracle3_8 --restore_epoch 2000000 --q_pred_calc batch'
 [18]='python3 train_value.py --run_group train_value1_3 --env_name humanoidmaze-large-navigate-oraclerep-v0 --agent ../agents/gcfql.py --dataset_dir ../../scratch/data/humanoidmaze-large-navigate-v0 --offline_steps 2000000 --save_interval 200000 --save_dir ../../scratch/gcfql/ --agent.alpha 300 --agent.actor_type best-of-n --agent.train_goal_proposer=True --agent.actor_hidden_dims 512,512,512,512 --agent.value_hidden_dims 512,512,512,512 --agent.batch_size 256 --agent.num_actions 8 --agent.num_qs 2 --json_path ../jsons/data.json --agent.awr_invtemp 1.0 --agent.discount 0.995 --restore_path ../../scratch/gcfql/horizon-reduction/gcfql_maze_oracle3_8/sd000_1447825734251.s_27684113_3.20250829_220125_147.gcfql_maze_oracle3_8 --restore_epoch 2000000 --q_pred_calc sample'
 [19]='python3 train_value.py --run_group train_value1_3 --env_name humanoidmaze-large-navigate-oraclerep-v0 --agent ../agents/gcfql.py --dataset_dir ../../scratch/data/humanoidmaze-large-navigate-v0 --offline_steps 2000000 --save_interval 200000 --save_dir ../../scratch/gcfql/ --agent.alpha 300 --agent.actor_type best-of-n --agent.train_goal_proposer=True --agent.actor_hidden_dims 512,512,512,512 --agent.value_hidden_dims 512,512,512,512 --agent.batch_size 256 --agent.num_actions 8 --agent.num_qs 2 --json_path ../jsons/data.json --agent.awr_invtemp 1.0 --agent.discount 0.995 --restore_path ../../scratch/gcfql/horizon-reduction/gcfql_maze_oracle3_8/sd000_1448582269550.s_27684707_5.20250830_020510_865.gcfql_maze_oracle3_8 --restore_epoch 2000000 --q_pred_calc batch'
 [20]='python3 train_value.py --run_group train_value1_3 --env_name humanoidmaze-large-navigate-oraclerep-v0 --agent ../agents/gcfql.py --dataset_dir ../../scratch/data/humanoidmaze-large-navigate-v0 --offline_steps 2000000 --save_interval 200000 --save_dir ../../scratch/gcfql/ --agent.alpha 300 --agent.actor_type best-of-n --agent.train_goal_proposer=True --agent.actor_hidden_dims 512,512,512,512 --agent.value_hidden_dims 512,512,512,512 --agent.batch_size 256 --agent.num_actions 8 --agent.num_qs 2 --json_path ../jsons/data.json --agent.awr_invtemp 1.0 --agent.discount 0.995 --restore_path ../../scratch/gcfql/horizon-reduction/gcfql_maze_oracle3_8/sd000_1448582269550.s_27684707_5.20250830_020510_865.gcfql_maze_oracle3_8 --restore_epoch 2000000 --q_pred_calc sample'
 [21]='python3 train_value.py --run_group train_value1_3 --env_name humanoidmaze-large-navigate-oraclerep-v0 --agent ../agents/gcfql.py --dataset_dir ../../scratch/data/humanoidmaze-large-navigate-v0 --offline_steps 2000000 --save_interval 200000 --save_dir ../../scratch/gcfql/ --agent.alpha 300 --agent.actor_type best-of-n --agent.train_goal_proposer=True --agent.actor_hidden_dims 512,512,512,512 --agent.value_hidden_dims 512,512,512,512 --agent.batch_size 256 --agent.num_actions 8 --agent.num_qs 2 --json_path ../jsons/data.json --agent.awr_invtemp 1.0 --agent.discount 0.995 --restore_path ../../scratch/gcfql/horizon-reduction/gcfql_maze_oracle3_8/sd000_1448722333294.s_27684112_2.20250829_220125_578.gcfql_maze_oracle3_8 --restore_epoch 2000000 --q_pred_calc batch'
 [22]='python3 train_value.py --run_group train_value1_3 --env_name humanoidmaze-large-navigate-oraclerep-v0 --agent ../agents/gcfql.py --dataset_dir ../../scratch/data/humanoidmaze-large-navigate-v0 --offline_steps 2000000 --save_interval 200000 --save_dir ../../scratch/gcfql/ --agent.alpha 300 --agent.actor_type best-of-n --agent.train_goal_proposer=True --agent.actor_hidden_dims 512,512,512,512 --agent.value_hidden_dims 512,512,512,512 --agent.batch_size 256 --agent.num_actions 8 --agent.num_qs 2 --json_path ../jsons/data.json --agent.awr_invtemp 1.0 --agent.discount 0.995 --restore_path ../../scratch/gcfql/horizon-reduction/gcfql_maze_oracle3_8/sd000_1448722333294.s_27684112_2.20250829_220125_578.gcfql_maze_oracle3_8 --restore_epoch 2000000 --q_pred_calc sample'
)

cd /home/jennifer/aorl/horizon_reduction

parallel --delay 20 --linebuffer -j 2 {1} ::: "${commands[@]:$COM_ID_S:$PARALLEL_N}"
